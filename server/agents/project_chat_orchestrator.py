import instructor
from atomic_agents import AgentConfig, AtomicAgent, BaseIOSchema, Field
from atomic_agents.agents.atomic_agent import ChatHistory
from config.datamodel import LlamaFarmConfig
from openai import OpenAI

from core.settings import settings


class ProjectChatOrchestratorAgentInputSchema(BaseIOSchema):
    """Input schema for the RAG QA agent."""

    chat_message: str = Field(
        ...,
        description="The chat message sent by the user to the assistant.",
    )


class ProjectChatOrchestratorAgentOutputSchema(BaseIOSchema):
    """Output schema for the project chat orchestrator agent."""

    chat_message: str = Field(
        ...,
        description=(
            "The chat message exchanged between the chat orchestrator and the user. "
            "This contains the markdown-enabled response generated by the chat agent."
        ),
    )


class ProjectChatOrchestratorAgent(
    AtomicAgent[
        ProjectChatOrchestratorAgentInputSchema,
        ProjectChatOrchestratorAgentOutputSchema,
    ]
):
    def __init__(self, config: AgentConfig):
        super().__init__(config)


class ProjectChatOrchestratorAgentFactory:
    @staticmethod
    def create_agent(model_strategy: LlamaFarmConfig) -> ProjectChatOrchestratorAgent:
        history = ChatHistory()
        history.add_message(
            "assistant",
            ProjectChatOrchestratorAgentOutputSchema(
                chat_message="Hello! How can I assist you today?"
            ),
        )

        # TODO: use the values from the project's model strategy config
        # base_url = model_strategy.base_url
        # api_key = model_strategy.api_key

        client = _get_client(model_strategy)

        agent = ProjectChatOrchestratorAgent(
            AgentConfig(
                client=client,
                model="gpt-4o-mini",
                history=ChatHistory(),
            )
        )
        agent.client.mode = instructor.Mode.JSON
        return agent


def _get_client(model_strategy: LlamaFarmConfig) -> instructor.client.Instructor:
    return instructor.from_openai(
        OpenAI(
            base_url=settings.ollama_host,
            api_key=settings.ollama_api_key,
        )
    )
