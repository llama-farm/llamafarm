# =============================================================================
# LlamaFarm Prompts System - Comprehensive Configuration Reference
# =============================================================================
# This file demonstrates ALL possible configuration options for the prompts system.
# Many options are commented out with their default values shown.
# Uncomment and modify as needed for your specific use case.
#
# Configuration Structure:
# 1. System Settings - Core configuration
# 2. Global Prompts - System-wide prompt modifications
# 3. Templates - Individual prompt templates
# 4. Strategies - Template selection strategies
# 5. Fallback Behavior - Error handling
# 6. Integrations - External system connections
# 7. Monitoring - Performance and logging
# 8. Environments - Environment-specific overrides
# =============================================================================

# -----------------------------------------------------------------------------
# SYSTEM SETTINGS
# -----------------------------------------------------------------------------
# Configuration name - identifies this configuration
name: "LlamaFarm Prompts Configuration"

# Configuration version - for tracking changes
version: "1.0.0"

# Human-readable description
description: "Comprehensive prompt management system with intelligent template selection"

# Whether the prompts system is enabled
enabled: true

# Default strategy to use when no specific strategy is requested
# Must match a strategy ID defined in the strategies section
default_strategy: "context_aware_strategy"

# -----------------------------------------------------------------------------
# GLOBAL PROMPTS
# -----------------------------------------------------------------------------
# Global prompts are applied to templates based on rules and conditions.
# They can modify system prompts, add prefixes/suffixes to user prompts.
global_prompts:
  # Example: System-wide context
  - global_id: "system_context"
    name: "System Context"
    description: "Provides general system context for all prompts"
    
    # System prompt - sets the AI assistant's role and behavior
    system_prompt: |
      You are a helpful AI assistant integrated with LlamaFarm, a comprehensive 
      document processing and RAG system. You have access to retrieved documents 
      and should provide accurate, helpful responses based on the available information.
    
    # Prefix prompt - added before the template content
    # prefix_prompt: "Please consider the following guidelines: "
    
    # Suffix prompt - added after the template content
    # suffix_prompt: "\n\nRemember to cite your sources."
    
    # Template patterns this global prompt applies to
    # Use wildcards (*) for pattern matching
    applies_to:
      - "*"  # Apply to all templates
      # - "qa_*"  # Apply to all QA templates
      # - "medical_*"  # Apply to medical templates
    
    # Templates to exclude (overrides applies_to)
    excludes: []
      # - "debug_*"
      # - "test_template"
    
    # Conditional application based on context
    conditions: {}
      # domain: "medical"  # Only apply when domain is medical
      # user_role: ["expert", "professional"]  # Only for certain user roles
      # language: "en"  # Only for English queries
    
    # Priority (lower number = higher priority, applied first)
    priority: 10
    
    # Whether this global prompt is active
    enabled: true
    
    # Tags for organization and filtering
    tags: []
      # - "production"
      # - "general"
    
    # Creator information
    # created_by: "admin@example.com"

  # Example: Quality guidelines
  - global_id: "quality_guidelines"
    name: "Quality Guidelines"
    description: "Ensures high-quality responses"
    prefix_prompt: |
      Please provide a clear, accurate, and helpful response. 
      If you're uncertain about something, acknowledge the uncertainty.
    applies_to: ["*"]
    excludes: 
      - "debug_*"
      - "test_*"
    priority: 20
    enabled: true

  # Example: Domain-specific context
  - global_id: "domain_medical"
    name: "Medical Domain Context"
    description: "Medical domain expertise context"
    system_prompt: |
      You are analyzing medical documents and should be precise, cite sources 
      when available, and note any limitations in the provided information. 
      Always recommend consulting healthcare professionals for medical decisions.
    applies_to:
      - "medical_*"
    conditions:
      domain: "medical"
    priority: 30
    enabled: true

  # Example: Language-specific formatting
  # - global_id: "spanish_format"
  #   name: "Spanish Language Formatting"
  #   description: "Formatting for Spanish language responses"
  #   prefix_prompt: "Por favor, responda en espa√±ol:"
  #   suffix_prompt: "\n\nGracias por su consulta."
  #   conditions:
  #     language: "es"
  #   priority: 40
  #   enabled: false

  # Example: Debug mode
  # - global_id: "debug_mode"
  #   name: "Debug Information"
  #   description: "Adds debug information to responses"
  #   suffix_prompt: |
  #     
  #     [DEBUG INFO]
  #     Template: {{ template_id }}
  #     Strategy: {{ strategy_id }}
  #     Context Keys: {{ context.keys() | join(', ') }}
  #   applies_to: ["debug_*"]
  #   conditions:
  #     debug_mode: true
  #   priority: 100
  #   enabled: false

# -----------------------------------------------------------------------------
# TEMPLATES
# -----------------------------------------------------------------------------
# Templates define the actual prompt structures.
# Each template has a unique ID and specific configuration.
templates:
  # Basic Question Answering Template
  qa_basic:
    # Unique identifier for this template
    template_id: "qa_basic"
    
    # Human-readable name
    name: "Basic Question Answering"
    
    # Template type/category
    type: "basic"  # Options: basic, chat, few_shot, advanced, domain_specific, agentic, langgraph_workflow
    
    # The actual prompt template (Jinja2 syntax)
    template: |
      Based on the following context:

      {{ context | format_documents }}

      Question: {{ query }}

      Answer:
    
    # Required input variables
    input_variables:
      - "context"
      - "query"
    
    # Optional variables with defaults
    optional_variables: []
      # - name: "max_length"
      #   default: 500
      # - name: "style"
      #   default: "concise"
    
    # Template metadata
    metadata:
      use_case: "general_qa"
      complexity: "low"  # Options: low, medium, high, expert
      domain: "general"
      tags:
        - "qa"
        - "basic"
        - "general"
      author: "LlamaFarm Team"
      created_at: "2025-07-31T10:00:00Z"
      updated_at: "2025-07-31T10:00:00Z"
      version: "1.0.0"
      description: "Simple question answering template for general queries"
      
      # Usage examples
      examples:
        - description: "Basic factual question"
          input:
            query: "What is machine learning?"
            context:
              - title: "ML Introduction"
                content: "Machine learning is a subset of AI that enables computers to learn from data."
          expected_output: "Based on the context, machine learning is a subset of AI that enables computers to learn from data."
      
      # Performance notes
      # performance_notes: "Optimized for quick responses. Best with contexts under 1000 tokens."
    
    # Advanced template features
    # global_prompts: ["custom_global_1", "custom_global_2"]  # Override global prompts
    
    # Preprocessing functions to apply
    # preprocessing_steps:
    #   - "normalize_whitespace"
    #   - "extract_keywords"
    #   - "detect_language"
    
    # Postprocessing functions to apply
    # postprocessing_steps:
    #   - "format_response"
    #   - "add_citations"
    #   - "check_factuality"
    
    # Input validation rules
    validation_rules:
      query:
        type: "str"
        min_length: 1
        max_length: 1000
        required: true
        # pattern: "^[A-Za-z0-9\\s\\?]+$"  # Regex pattern
      context:
        type: "list"
        required: true
        # min_items: 1
        # max_items: 10
        # item_validation:
        #   type: "dict"
        #   required_fields: ["content"]
    
    # LangGraph workflow configuration
    # langgraph_config:
    #   workflow_id: "qa_workflow"
    #   nodes:
    #     - id: "parse_query"
    #       type: "processor"
    #     - id: "retrieve_context"
    #       type: "retriever"
    #     - id: "generate_answer"
    #       type: "generator"
    #   edges:
    #     - from: "parse_query"
    #       to: "retrieve_context"
    #     - from: "retrieve_context"
    #       to: "generate_answer"
    
    # Conditions for automatic template selection
    # conditions:
    #   query_type: "question"
    #   complexity: ["low", "medium"]
    #   language: "en"
    
    # Fallback templates if this one fails
    # fallback_templates: ["qa_detailed", "general_response"]

  # Medical Question Answering Template (Domain-Specific)
  medical_qa:
    template_id: "medical_qa"
    name: "Medical Question Answering"
    type: "domain_specific"
    template: |
      Medical Context:
      {{ context | format_documents }}

      Medical Question: {{ query }}

      Please provide a medically accurate response based on the provided context. 
      If the information is not sufficient, indicate what additional information would be needed.
      
      Medical Response:
    input_variables:
      - "context"
      - "query"
    metadata:
      use_case: "medical_qa"
      complexity: "high"
      domain: "medical"
      tags:
        - "medical"
        - "healthcare"
        - "specialized"
      description: "Specialized template for medical domain questions"
    validation_rules:
      query:
        type: "str"
        required: true
      context:
        type: "list"
        required: true

  # Multi-Agent Coordination Template (Agentic)
  agent_coordinator:
    template_id: "agent_coordinator"
    name: "Multi-Agent Coordination"
    type: "agentic"
    template: |
      Coordinate multiple agents to achieve: {{ objective }}

      Available Agents:
      {% for agent in agents %}
      - {{ agent.name }} ({{ agent.specialty }}): {{ agent.role }}
        Capabilities: {{ agent.capabilities | join(', ') }}
      {% endfor %}

      {% if coordination_mode %}
      Coordination Mode: {{ coordination_mode }}
      {% endif %}

      Create a coordination plan that:
      1. Assigns specific tasks to each agent based on their capabilities
      2. Defines the order of operations and dependencies
      3. Specifies how agents should communicate and share results
      4. Includes success criteria and checkpoints
      5. Handles potential failure scenarios

      Coordination Plan:
    input_variables:
      - "objective"
      - "agents"
    optional_variables:
      - "coordination_mode"
    metadata:
      use_case: "multi_agent_coordination"
      complexity: "high"
      domain: "agentic"
      tags:
        - "agents"
        - "coordination"
        - "orchestration"
      description: "Coordinates multiple AI agents for complex tasks"

# Additional templates would be defined here...
# (Showing structure, actual file contains all 20 templates)

# -----------------------------------------------------------------------------
# STRATEGIES
# -----------------------------------------------------------------------------
# Strategies determine how templates are selected based on context.
strategies:
  # Context-Aware Strategy
  context_aware_strategy:
    strategy_id: "context_aware_strategy"
    name: "Context-Aware Template Selection"
    description: "Selects templates based on query analysis and context"
    type: "context_aware"  # Options: static, rule_based, context_aware, ml_driven, a_b_test, performance_based, langgraph_orchestrated
    enabled: true
    
    # Fallback template if no rules match
    fallback_template: "qa_basic"
    
    # Additional configuration
    # confidence_threshold: 0.7  # Minimum confidence for selection
    # cache_selections: true  # Cache template selections
    # cache_ttl: 3600  # Cache time-to-live in seconds
    
    # Performance tracking
    # track_performance: true
    # performance_window: "7d"  # Track last 7 days
    # optimization_interval: "daily"  # Re-optimize daily

  # Rule-Based Strategy
  rule_based_strategy:
    strategy_id: "rule_based_strategy"
    name: "Rule-Based Selection"
    description: "Selects templates based on defined rules"
    type: "rule_based"
    enabled: true
    fallback_template: "qa_basic"
    
    # Strategy rules
    rules:
      - rule_id: "medical_domain_rule"
        name: "Medical Domain Rule"
        description: "Select medical template for medical queries"
        field: "domain"
        operator: "=="  # Options: ==, !=, >, <, >=, <=, in, not_in, contains, not_contains, starts_with, ends_with, regex_match
        value: "medical"
        template_id: "medical_qa"
        priority: 10  # Lower = higher priority
        enabled: true
        
        # Additional AND conditions
        # additional_conditions:
        #   - field: "user_role"
        #     operator: "in"
        #     value: ["doctor", "nurse", "medical_professional"]
        
        # Alternative OR conditions
        # or_conditions:
        #   - field: "query_type"
        #     operator: "=="
        #     value: "diagnosis"
        #   - field: "query_type"
        #     operator: "=="
        #     value: "treatment"
        
        # Rule metadata
        # tags: ["medical", "priority"]
        # created_by: "medical_team@example.com"
      
      - rule_id: "code_analysis_rule"
        field: "domain"
        operator: "=="
        value: "software"
        template_id: "code_analysis"
        priority: 20
        enabled: true
      
      - rule_id: "chat_conversation_rule"
        field: "query_type"
        operator: "=="
        value: "conversation"
        template_id: "chat_assistant"
        priority: 30
        enabled: true

  # A/B Testing Strategy
  # ab_test_strategy:
  #   strategy_id: "ab_test_strategy"
  #   name: "A/B Testing Strategy"
  #   description: "Tests different templates to find the best performer"
  #   type: "a_b_test"
  #   enabled: false
  #   
  #   # A/B test configuration
  #   variants:
  #     - template_id: "qa_basic"
  #       weight: 50  # 50% of traffic
  #     - template_id: "qa_detailed"
  #       weight: 50  # 50% of traffic
  #   
  #   # Test metrics
  #   metrics:
  #     - "response_quality"
  #     - "user_satisfaction"
  #     - "response_time"
  #   
  #   # Test duration
  #   test_duration: "30d"
  #   minimum_sample_size: 1000

  # ML-Driven Strategy
  # ml_strategy:
  #   strategy_id: "ml_strategy"
  #   name: "Machine Learning Strategy"
  #   description: "Uses ML model to select best template"
  #   type: "ml_driven"
  #   enabled: false
  #   
  #   # Model configuration
  #   model:
  #     type: "classification"
  #     path: "models/template_selector.pkl"
  #     features:
  #       - "query_length"
  #       - "query_complexity"
  #       - "domain_embedding"
  #       - "user_history"
  #   
  #   # Model update settings
  #   update_frequency: "weekly"
  #   minimum_training_samples: 10000
  #   
  #   # Fallback behavior
  #   fallback_template: "qa_basic"
  #   use_fallback_below_confidence: 0.6

# -----------------------------------------------------------------------------
# FALLBACK BEHAVIOR
# -----------------------------------------------------------------------------
# System-wide fallback configuration for error handling
fallback_behavior:
  # Default fallback template
  default_fallback: "qa_basic"
  
  # Maximum retry attempts
  max_retries: 3
  
  # Retry delay in milliseconds
  retry_delay: 1000
  
  # Exponential backoff
  # exponential_backoff: true
  # backoff_multiplier: 2
  
  # Error handling mode
  error_mode: "graceful"  # Options: graceful, strict, silent
  
  # Log errors
  log_errors: true
  
  # Send error notifications
  # notify_on_error: true
  # notification_webhook: "https://example.com/webhook"
  
  # Fallback chain (try these templates in order)
  # fallback_chain:
  #   - "qa_basic"
  #   - "general_response"
  #   - "error_message"

# -----------------------------------------------------------------------------
# INTEGRATIONS
# -----------------------------------------------------------------------------
# Configuration for external system integrations
integrations:
  # RAG System Integration
  rag:
    enabled: true
    # Vector store configuration
    vector_store:
      type: "chromadb"
      collection: "documents"
      # connection:
      #   host: "localhost"
      #   port: 8000
    
    # Retrieval settings
    retrieval:
      top_k: 5
      # score_threshold: 0.7
      # rerank: true
      # rerank_model: "cross-encoder/ms-marco-MiniLM-L-6-v2"
  
  # LangGraph Integration
  # langgraph:
  #   enabled: false
  #   workflows:
  #     - id: "qa_workflow"
  #       path: "workflows/qa_workflow.py"
  #     - id: "agent_workflow"
  #       path: "workflows/agent_workflow.py"
  #   
  #   # Execution settings
  #   execution:
  #     timeout: 30000  # milliseconds
  #     max_parallel: 5
  #     retry_failed_nodes: true
  
  # LLM Providers
  # llm_providers:
  #   openai:
  #     enabled: true
  #     api_key: "${OPENAI_API_KEY}"  # Environment variable
  #     model: "gpt-4"
  #     temperature: 0.7
  #     max_tokens: 2000
  #   
  #   anthropic:
  #     enabled: false
  #     api_key: "${ANTHROPIC_API_KEY}"
  #     model: "claude-3-opus-20240229"
  #   
  #   ollama:
  #     enabled: false
  #     base_url: "http://localhost:11434"
  #     model: "llama3"

# -----------------------------------------------------------------------------
# MONITORING
# -----------------------------------------------------------------------------
# Performance monitoring and logging configuration
monitoring:
  # Enable monitoring
  enabled: true
  
  # Logging configuration
  logging:
    level: "INFO"  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
    # format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    # file: "logs/prompts.log"
    # max_size: "100MB"
    # backup_count: 5
  
  # Metrics collection
  # metrics:
  #   enabled: true
  #   backend: "prometheus"  # Options: prometheus, statsd, cloudwatch
  #   endpoint: "http://localhost:9090"
  #   
  #   # Metrics to track
  #   track:
  #     - "template_usage"
  #     - "strategy_performance"
  #     - "response_time"
  #     - "error_rate"
  #     - "token_usage"
  #   
  #   # Collection interval
  #   interval: 60  # seconds
  
  # Performance profiling
  # profiling:
  #   enabled: false
  #   sample_rate: 0.1  # Profile 10% of requests
  #   output: "profiles/"
  
  # Alerting
  # alerting:
  #   enabled: false
  #   providers:
  #     - type: "email"
  #       smtp_host: "smtp.example.com"
  #       smtp_port: 587
  #       from_email: "alerts@example.com"
  #       to_emails: ["admin@example.com"]
  #     
  #     - type: "slack"
  #       webhook_url: "${SLACK_WEBHOOK_URL}"
  #       channel: "#alerts"
  #   
  #   # Alert rules
  #   rules:
  #     - name: "high_error_rate"
  #       condition: "error_rate > 0.05"  # 5% error rate
  #       severity: "critical"
  #       message: "Error rate exceeded 5%"
  #     
  #     - name: "slow_response"
  #       condition: "p95_response_time > 5000"  # 5 seconds
  #       severity: "warning"
  #       message: "Response time P95 exceeded 5 seconds"

# -----------------------------------------------------------------------------
# ENVIRONMENTS
# -----------------------------------------------------------------------------
# Environment-specific overrides
environments:
  # Development environment
  development:
    # Override monitoring for development
    monitoring:
      logging:
        level: "DEBUG"
    
    # # Enable debug templates
    # templates:
    #   debug_template:
    #     template_id: "debug_template"
    #     name: "Debug Template"
    #     type: "basic"
    #     template: "DEBUG: {{ query }}\nContext Keys: {{ context.keys() }}"
    #     input_variables: ["query", "context"]
  
  # Production environment
  production:
    # Stricter settings for production
    enabled: true
    fallback_behavior:
      error_mode: "strict"
      max_retries: 5
    
    monitoring:
      logging:
        level: "WARNING"
      # metrics:
      #   enabled: true
      # alerting:
      #   enabled: true
  
  # Testing environment
  # testing:
  #   # Disable certain features for testing
  #   integrations:
  #     rag:
  #       enabled: false
  #   
  #   # Use test templates
  #   default_strategy: "test_strategy"
  #   
  #   # Test-specific templates
  #   templates:
  #     test_template:
  #       template_id: "test_template"
  #       name: "Test Template"
  #       type: "basic"
  #       template: "TEST RESPONSE: {{ query }}"
  #       input_variables: ["query"]

# -----------------------------------------------------------------------------
# ADVANCED FEATURES (Uncomment to enable)
# -----------------------------------------------------------------------------

# # Caching configuration
# caching:
#   enabled: true
#   backend: "redis"  # Options: redis, memcached, in_memory
#   connection:
#     host: "localhost"
#     port: 6379
#   
#   # Cache settings
#   ttl: 3600  # Time to live in seconds
#   max_size: "1GB"
#   
#   # What to cache
#   cache_items:
#     - "template_renders"
#     - "strategy_selections"
#     - "llm_responses"

# # Security configuration
# security:
#   # Input sanitization
#   sanitize_inputs: true
#   max_input_length: 10000
#   
#   # Rate limiting
#   rate_limiting:
#     enabled: true
#     requests_per_minute: 60
#     requests_per_hour: 1000
#   
#   # API key management
#   api_keys:
#     required: false
#     header_name: "X-API-Key"
#     # keys:
#     #   - key: "dev-key-123"
#     #     name: "Development Key"
#     #     rate_limit_override: 1000
#   
#   # Content filtering
#   content_filtering:
#     enabled: false
#     block_patterns:
#       - "(?i)password"
#       - "(?i)secret"
#       - "(?i)api[_-]?key"

# # Feature flags
# feature_flags:
#   # Enable experimental features
#   enable_experimental: false
#   
#   # Specific features
#   features:
#     multi_turn_conversation: true
#     streaming_responses: false
#     async_processing: false
#     auto_retry: true
#     template_versioning: false

# # Custom processors
# processors:
#   # Preprocessing functions
#   preprocessors:
#     normalize_whitespace:
#       enabled: true
#       function: "prompts.processors.normalize_whitespace"
#     
#     detect_language:
#       enabled: false
#       function: "prompts.processors.detect_language"
#       config:
#         default_language: "en"
#   
#   # Postprocessing functions
#   postprocessors:
#     format_response:
#       enabled: true
#       function: "prompts.processors.format_response"
#       config:
#         max_length: 2000
#         add_line_breaks: true
#     
#     add_citations:
#       enabled: false
#       function: "prompts.processors.add_citations"
#       config:
#         citation_style: "numeric"  # Options: numeric, author_year, footnote

# =============================================================================
# END OF CONFIGURATION
# =============================================================================