template_id: rag_evaluation
name: RAG System Evaluation
type: domain_specific
template: '# RAG System Evaluation


  ## Query

  {{ query }}


  ## Retrieved Documents

  {{ retrieved_docs | format_documents }}


  ## Generated Response

  {{ generated_response }}


  ## Ground Truth (if available)

  {{ ground_truth }}


  üîç **RAG SYSTEM EVALUATION**


  üìö **Retrieval Quality Assessment**

  ‚Ä¢ **Relevance**: Are the retrieved documents relevant to the query?

  ‚Ä¢ **Coverage**: Do the documents contain information needed to answer the query?

  ‚Ä¢ **Diversity**: Do the documents provide diverse perspectives or complementary
  information?

  ‚Ä¢ **Ranking**: Are the most relevant documents ranked highest?


  üéØ **Answer Quality Assessment**

  ‚Ä¢ **Accuracy**: Is the generated response factually correct?

  ‚Ä¢ **Completeness**: Does the response fully address the query?

  ‚Ä¢ **Coherence**: Is the response well-structured and coherent?

  ‚Ä¢ **Citation**: Does the response appropriately reference the source documents?


  üîó **Retrieval-Generation Alignment**

  ‚Ä¢ **Grounding**: Is the response properly grounded in the retrieved documents?

  ‚Ä¢ **Hallucination Check**: Does the response contain information not present in
  the retrieved docs?

  ‚Ä¢ **Consistency**: Is the response consistent with the retrieved information?

  ‚Ä¢ **Source Attribution**: Are claims properly attributed to sources?


  üìä **Scoring Matrix**


  **Retrieval Metrics:**

  ‚Ä¢ Relevance: [Score 1-5] - [Justification]

  ‚Ä¢ Coverage: [Score 1-5] - [Justification]

  ‚Ä¢ Diversity: [Score 1-5] - [Justification]

  ‚Ä¢ Ranking Quality: [Score 1-5] - [Justification]


  **Generation Metrics:**

  ‚Ä¢ Accuracy: [Score 1-5] - [Justification]

  ‚Ä¢ Completeness: [Score 1-5] - [Justification]

  ‚Ä¢ Coherence: [Score 1-5] - [Justification]

  ‚Ä¢ Citation Quality: [Score 1-5] - [Justification]


  **Alignment Metrics:**

  ‚Ä¢ Grounding: [Score 1-5] - [Justification]

  ‚Ä¢ Hallucination: [Score 1-5] - [Lower = more hallucination]

  ‚Ä¢ Consistency: [Score 1-5] - [Justification]


  **Overall RAG Score**: [Total]/55

  **Grade**: [Excellent/Good/Fair/Poor]


  ‚ö†Ô∏è **Key Issues Identified**

  ‚Ä¢ [List major problems or concerns]


  ‚úÖ **Strengths**

  ‚Ä¢ [List what worked well]


  üîß **Recommendations**

  ‚Ä¢ [Specific suggestions for improvement]'
input_variables:
- query
- retrieved_docs
- generated_response
optional_variables:
- ground_truth
metadata:
  use_case: rag_evaluation
  complexity: high
  domain: evaluation
  description: Comprehensive evaluation template for RAG system performance
  tags:
  - rag
  - evaluation
  - retrieval
  - generation
  - quality_assessment
  author: LlamaFarm Team
  examples:
  - description: Evaluating RAG response quality
    input:
      query: What are the benefits of renewable energy?
      retrieved_docs:
      - title: Solar Energy Benefits
        content: Solar energy reduces carbon emissions and provides long-term cost
          savings.
      - title: Wind Power Advantages
        content: Wind power is sustainable and creates jobs in rural communities.
      generated_response: Renewable energy offers multiple benefits including reduced
        carbon emissions from solar power, long-term cost savings, job creation in
        rural areas through wind power, and overall sustainability.
      ground_truth: Benefits include environmental protection, economic advantages,
        and energy independence.
    expected_output: '**Retrieval Quality**: 4/5 - Documents are relevant and provide
      good coverage

      **Generation Quality**: 4/5 - Response is accurate and well-grounded

      **Overall RAG Score**: 44/55'
validation_rules:
  query:
    type: str
    min_length: 5
    max_length: 1000
    required: true
  retrieved_docs:
    type: list
    required: true
  generated_response:
    type: str
    min_length: 10
    max_length: 5000
    required: true
  ground_truth:
    type: str
    required: false
