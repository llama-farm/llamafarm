{"instruction": "How do I read a CSV file in Python?", "input": "", "output": "Use the pandas library for the most convenient CSV reading:\n\n```python\nimport pandas as pd\n\n# Read CSV file\ndf = pd.read_csv('data.csv')\nprint(df.head())  # Show first 5 rows\n```\n\nAlternatively, use the built-in csv module:\n\n```python\nimport csv\n\nwith open('data.csv', 'r') as file:\n    csv_reader = csv.reader(file)\n    for row in csv_reader:\n        print(row)\n```\n\n**Best Practice**: Always handle file operations with proper error handling and use context managers (with statements) to ensure files are properly closed."}
{"instruction": "What's the difference between lists and tuples in Python?", "input": "", "output": "Key differences between lists and tuples:\n\n**Lists** - Mutable (can be changed):\n```python\nmy_list = [1, 2, 3]\nmy_list.append(4)  # Works fine\nmy_list[0] = 10    # Can modify elements\nprint(my_list)     # [10, 2, 3, 4]\n```\n\n**Tuples** - Immutable (cannot be changed):\n```python\nmy_tuple = (1, 2, 3)\n# my_tuple.append(4)    # Error! No append method\n# my_tuple[0] = 10      # Error! Cannot modify\nprint(my_tuple)         # (1, 2, 3)\n```\n\n**When to use**:\n- Use lists for collections that need to change\n- Use tuples for fixed data like coordinates (x, y) or database records\n- Tuples are slightly faster and can be dictionary keys"}
{"instruction": "How do I handle exceptions in Python?", "input": "", "output": "Use try-except blocks to handle exceptions gracefully:\n\n```python\ntry:\n    # Code that might raise an exception\n    result = 10 / 0\nexcept ZeroDivisionError:\n    print(\"Cannot divide by zero!\")\nexcept ValueError as e:\n    print(f\"Value error: {e}\")\nexcept Exception as e:\n    print(f\"Unexpected error: {e}\")\nelse:\n    print(\"No exceptions occurred\")\nfinally:\n    print(\"This always executes\")\n```\n\n**Best Practices**:\n- Catch specific exceptions rather than using bare `except:`\n- Use `finally` for cleanup code that must always run\n- Log exceptions for debugging purposes\n- Don't ignore exceptions silently"}
{"instruction": "How do I create a class in Python?", "input": "", "output": "Define a class using the `class` keyword:\n\n```python\nclass Person:\n    def __init__(self, name, age):\n        self.name = name\n        self.age = age\n    \n    def greet(self):\n        return f\"Hello, I'm {self.name} and I'm {self.age} years old\"\n    \n    def have_birthday(self):\n        self.age += 1\n        return f\"{self.name} is now {self.age}\"\n\n# Create and use objects\nperson1 = Person(\"Alice\", 25)\nprint(person1.greet())\nprint(person1.have_birthday())\n```\n\n**Key Concepts**:\n- `__init__` is the constructor method\n- `self` refers to the instance of the class\n- Methods are functions defined inside a class\n- Attributes store data specific to each instance"}
{"instruction": "How do I work with dictionaries in Python?", "input": "", "output": "Dictionaries store key-value pairs and are very versatile:\n\n```python\n# Creating dictionaries\nstudent = {'name': 'John', 'age': 20, 'grade': 'A'}\n\n# Accessing values\nprint(student['name'])        # John\nprint(student.get('age'))     # 20 (safer method)\n\n# Adding/updating values\nstudent['major'] = 'Computer Science'\nstudent['age'] = 21\n\n# Iterating\nfor key, value in student.items():\n    print(f\"{key}: {value}\")\n\n# Dictionary methods\nkeys = student.keys()\nvalues = student.values()\n```\n\n**Best Practices**:\n- Use `.get()` to avoid KeyError exceptions\n- Dictionary comprehensions: `{k: v for k, v in items}`\n- Use dictionaries for mappings and lookups"}
{"instruction": "How do I read and write files in Python?", "input": "", "output": "Always use context managers (with statements) for file operations:\n\n**Reading files:**\n```python\n# Read entire file\nwith open('file.txt', 'r') as file:\n    content = file.read()\n    print(content)\n\n# Read line by line\nwith open('file.txt', 'r') as file:\n    for line in file:\n        print(line.strip())\n```\n\n**Writing files:**\n```python\n# Write to file (overwrites existing)\nwith open('output.txt', 'w') as file:\n    file.write('Hello, World!\\n')\n\n# Append to file\nwith open('output.txt', 'a') as file:\n    file.write('Additional line\\n')\n```\n\n**Best Practices**:\n- Always use `with` statements for automatic file closing\n- Handle encoding explicitly: `open('file.txt', 'r', encoding='utf-8')`\n- Use appropriate modes: 'r' (read), 'w' (write), 'a' (append)"}
{"instruction": "How do I use list comprehensions in Python?", "input": "", "output": "List comprehensions provide a concise way to create lists:\n\n**Basic syntax:** `[expression for item in iterable if condition]`\n\n```python\n# Traditional approach\nnumbers = [1, 2, 3, 4, 5]\nsquares = []\nfor n in numbers:\n    if n % 2 == 0:\n        squares.append(n ** 2)\n\n# List comprehension\nsquares = [n ** 2 for n in numbers if n % 2 == 0]\nprint(squares)  # [4, 16]\n\n# More examples\nwords = ['hello', 'world', 'python']\ncapitalized = [word.upper() for word in words]\nlong_words = [word for word in words if len(word) > 5]\n\n# Nested comprehensions\nmatrix = [[1, 2, 3], [4, 5, 6]]\nflattened = [num for row in matrix for num in row]\n```\n\n**Best Practice**: Use list comprehensions for simple transformations, but use regular loops for complex logic."}
{"instruction": "How do I work with functions in Python?", "input": "", "output": "Functions are defined with the `def` keyword:\n\n```python\n# Basic function\ndef greet(name):\n    return f\"Hello, {name}!\"\n\n# Function with default parameters\ndef calculate_area(length, width=1):\n    return length * width\n\n# Function with variable arguments\ndef sum_all(*args):\n    return sum(args)\n\n# Function with keyword arguments\ndef create_profile(**kwargs):\n    return kwargs\n\n# Using functions\nprint(greet(\"Alice\"))\nprint(calculate_area(5))      # Uses default width=1\nprint(sum_all(1, 2, 3, 4))   # 10\nprint(create_profile(name=\"John\", age=25))\n```\n\n**Best Practices**:\n- Use descriptive function names\n- Include docstrings to document your functions\n- Keep functions focused on a single task\n- Use type hints for better code documentation"}
{"instruction": "How do I install and use packages in Python?", "input": "", "output": "Use pip to install packages from PyPI:\n\n**Installing packages:**\n```bash\n# Install a package\npip install requests\n\n# Install specific version\npip install django==3.2\n\n# Install from requirements file\npip install -r requirements.txt\n\n# Upgrade a package\npip install --upgrade numpy\n```\n\n**Using packages:**\n```python\n# Import entire module\nimport requests\nresponse = requests.get('https://api.github.com')\n\n# Import specific functions\nfrom datetime import datetime, timedelta\nnow = datetime.now()\n\n# Import with alias\nimport numpy as np\narray = np.array([1, 2, 3])\n```\n\n**Best Practices**:\n- Use virtual environments to isolate project dependencies\n- Keep a requirements.txt file for your projects\n- Check package documentation before using"}
{"instruction": "How do I debug Python code effectively?", "input": "", "output": "Use multiple debugging techniques:\n\n**Print statements (simple debugging):**\n```python\ndef calculate_average(numbers):\n    print(f\"Input: {numbers}\")  # Debug print\n    total = sum(numbers)\n    print(f\"Total: {total}\")     # Debug print\n    return total / len(numbers)\n```\n\n**Using the debugger:**\n```python\nimport pdb\n\ndef problematic_function(x, y):\n    pdb.set_trace()  # Breakpoint\n    result = x / y\n    return result\n```\n\n**Exception handling with logging:**\n```python\nimport logging\n\nlogging.basicConfig(level=logging.DEBUG)\nlogger = logging.getLogger(__name__)\n\ntry:\n    result = risky_operation()\nexcept Exception as e:\n    logger.error(f\"Error occurred: {e}\")\n    raise\n```\n\n**Best Practices**:\n- Use IDE debuggers for complex issues\n- Remove debug prints before production\n- Use logging instead of print for production code"}
{"instruction": "How do I work with JSON data in Python?", "input": "", "output": "Use the json module to work with JSON data:\n\n```python\nimport json\n\n# Convert Python object to JSON string\ndata = {'name': 'Alice', 'age': 30, 'city': 'New York'}\njson_string = json.dumps(data, indent=2)\nprint(json_string)\n\n# Convert JSON string to Python object\njson_data = '{\"name\": \"Bob\", \"age\": 25}'\npython_dict = json.loads(json_data)\nprint(python_dict['name'])  # Bob\n\n# Read JSON from file\nwith open('data.json', 'r') as file:\n    data = json.load(file)\n\n# Write JSON to file\nwith open('output.json', 'w') as file:\n    json.dump(data, file, indent=2)\n```\n\n**Best Practices**:\n- Use `indent` parameter for readable JSON output\n- Handle JSON parsing errors with try-except blocks\n- Use custom encoders for non-serializable objects like datetime"}
{"instruction": "How do I create and use decorators in Python?", "input": "", "output": "Decorators are functions that modify other functions:\n\n```python\n# Basic decorator\ndef my_decorator(func):\n    def wrapper(*args, **kwargs):\n        print(f\"Calling {func.__name__}\")\n        result = func(*args, **kwargs)\n        print(f\"Finished {func.__name__}\")\n        return result\n    return wrapper\n\n@my_decorator\ndef greet(name):\n    return f\"Hello, {name}!\"\n\n# Decorator with parameters\ndef repeat(times):\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            for _ in range(times):\n                result = func(*args, **kwargs)\n            return result\n        return wrapper\n    return decorator\n\n@repeat(3)\ndef say_hello():\n    print(\"Hello!\")\n```\n\n**Common Use Cases**:\n- Timing function execution\n- Logging function calls\n- Authentication checks\n- Caching results"}
{"instruction": "How do I work with regular expressions in Python?", "input": "", "output": "Use the re module for pattern matching:\n\n```python\nimport re\n\n# Basic pattern matching\ntext = \"My phone number is 555-123-4567\"\npattern = r'\\d{3}-\\d{3}-\\d{4}'\nmatch = re.search(pattern, text)\nif match:\n    print(f\"Found: {match.group()}\")\n\n# Find all matches\nemail_text = \"Contact: john@example.com or jane@test.org\"\nemail_pattern = r'[\\w.-]+@[\\w.-]+\\.\\w+'\nemails = re.findall(email_pattern, email_text)\nprint(emails)  # ['john@example.com', 'jane@test.org']\n\n# Replace patterns\ntext = \"Hello world\"\nresult = re.sub(r'world', 'Python', text)\nprint(result)  # \"Hello Python\"\n\n# Using groups\ndate_pattern = r'(\\d{4})-(\\d{2})-(\\d{2})'\nmatch = re.search(date_pattern, \"Today is 2023-12-25\")\nif match:\n    year, month, day = match.groups()\n    print(f\"Year: {year}, Month: {month}, Day: {day}\")\n```\n\n**Best Practices**:\n- Use raw strings (r'') for regex patterns\n- Compile patterns you'll use multiple times\n- Test regex patterns with online tools"}
{"instruction": "How do I work with dates and times in Python?", "input": "", "output": "Use the datetime module for date and time operations:\n\n```python\nfrom datetime import datetime, date, timedelta\n\n# Current date and time\nnow = datetime.now()\ntoday = date.today()\nprint(f\"Now: {now}\")\nprint(f\"Today: {today}\")\n\n# Creating specific dates\nbirthday = datetime(1990, 5, 15, 14, 30)  # Year, month, day, hour, minute\nprint(birthday)\n\n# Formatting dates\nformatted = now.strftime(\"%Y-%m-%d %H:%M:%S\")\nprint(f\"Formatted: {formatted}\")\n\n# Parsing date strings\ndate_string = \"2023-12-25\"\nparsed_date = datetime.strptime(date_string, \"%Y-%m-%d\")\n\n# Date arithmetic\ntomorrow = today + timedelta(days=1)\nlast_week = today - timedelta(weeks=1)\nprint(f\"Tomorrow: {tomorrow}\")\nprint(f\"Last week: {last_week}\")\n```\n\n**Common Format Codes**:\n- %Y: 4-digit year\n- %m: Month as number\n- %d: Day of month\n- %H: Hour (24-hour)\n- %M: Minute\n- %S: Second"}
{"instruction": "How do I use generators in Python?", "input": "", "output": "Generators create iterators that yield values on-demand:\n\n```python\n# Generator function\ndef countdown(n):\n    while n > 0:\n        yield n\n        n -= 1\n\n# Using the generator\nfor num in countdown(5):\n    print(num)  # Prints 5, 4, 3, 2, 1\n\n# Generator expression\nsquares = (x**2 for x in range(10))\nprint(list(squares))  # [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n\n# Fibonacci generator\ndef fibonacci():\n    a, b = 0, 1\n    while True:\n        yield a\n        a, b = b, a + b\n\n# Get first 10 Fibonacci numbers\nfib = fibonacci()\nfirst_10 = [next(fib) for _ in range(10)]\nprint(first_10)  # [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\n```\n\n**Benefits**:\n- Memory efficient for large datasets\n- Lazy evaluation (computed on-demand)\n- Can represent infinite sequences"}
{"instruction": "How do I implement a binary search algorithm?", "input": "", "output": "Binary search works on sorted arrays with O(log n) time complexity:\n\n```python\ndef binary_search(arr, target):\n    left, right = 0, len(arr) - 1\n    \n    while left <= right:\n        mid = (left + right) // 2\n        \n        if arr[mid] == target:\n            return mid  # Found target at index mid\n        elif arr[mid] < target:\n            left = mid + 1  # Search right half\n        else:\n            right = mid - 1  # Search left half\n    \n    return -1  # Target not found\n\n# Recursive version\ndef binary_search_recursive(arr, target, left=0, right=None):\n    if right is None:\n        right = len(arr) - 1\n    \n    if left > right:\n        return -1\n    \n    mid = (left + right) // 2\n    \n    if arr[mid] == target:\n        return mid\n    elif arr[mid] < target:\n        return binary_search_recursive(arr, target, mid + 1, right)\n    else:\n        return binary_search_recursive(arr, target, left, mid - 1)\n\n# Example usage\nsorted_array = [1, 3, 5, 7, 9, 11, 13, 15]\nindex = binary_search(sorted_array, 7)\nprint(f\"Found 7 at index: {index}\")  # Found 7 at index: 3\n```\n\n**Key Points**:\n- Array must be sorted\n- Much faster than linear search for large datasets\n- Time complexity: O(log n)"}
{"instruction": "How do I work with sets in Python?", "input": "", "output": "Sets are unordered collections of unique elements:\n\n```python\n# Creating sets\nfruits = {'apple', 'banana', 'orange'}\nnumbers = set([1, 2, 3, 2, 1])  # Duplicates removed\nprint(numbers)  # {1, 2, 3}\n\n# Adding and removing elements\nfruits.add('grape')\nfruits.remove('banana')  # Raises KeyError if not found\nfruits.discard('kiwi')   # No error if not found\n\n# Set operations\nset1 = {1, 2, 3, 4}\nset2 = {3, 4, 5, 6}\n\n# Union (all elements)\nunion = set1 | set2  # or set1.union(set2)\nprint(union)  # {1, 2, 3, 4, 5, 6}\n\n# Intersection (common elements)\nintersection = set1 & set2  # or set1.intersection(set2)\nprint(intersection)  # {3, 4}\n\n# Difference (in set1 but not set2)\ndifference = set1 - set2  # or set1.difference(set2)\nprint(difference)  # {1, 2}\n\n# Checking membership\nprint(3 in set1)  # True\nprint(7 in set1)  # False\n```\n\n**Use Cases**:\n- Removing duplicates from lists\n- Mathematical set operations\n- Fast membership testing"}
{"instruction": "How do I create and use virtual environments?", "input": "", "output": "Virtual environments isolate project dependencies:\n\n**Creating virtual environment:**\n```bash\n# Using venv (Python 3.3+)\npython -m venv myproject\n\n# Using virtualenv\nvirtualenv myproject\n```\n\n**Activating virtual environment:**\n```bash\n# On Windows\nmyproject\\Scripts\\activate\n\n# On macOS/Linux\nsource myproject/bin/activate\n```\n\n**Installing packages:**\n```bash\n# Install packages in virtual environment\npip install requests pandas numpy\n\n# Create requirements file\npip freeze > requirements.txt\n\n# Install from requirements file\npip install -r requirements.txt\n```\n\n**Deactivating:**\n```bash\ndeactivate\n```\n\n**Best Practices**:\n- Create a new virtual environment for each project\n- Keep requirements.txt updated\n- Don't commit virtual environment to version control\n- Use descriptive names for virtual environments"}
{"instruction": "How do I implement a simple sorting algorithm?", "input": "", "output": "Here's bubble sort, a simple sorting algorithm:\n\n```python\ndef bubble_sort(arr):\n    n = len(arr)\n    \n    # Traverse through all elements\n    for i in range(n):\n        # Flag to optimize - if no swaps, array is sorted\n        swapped = False\n        \n        # Last i elements are already sorted\n        for j in range(0, n - i - 1):\n            # Swap if current element is greater than next\n            if arr[j] > arr[j + 1]:\n                arr[j], arr[j + 1] = arr[j + 1], arr[j]\n                swapped = True\n        \n        # If no swapping occurred, array is sorted\n        if not swapped:\n            break\n    \n    return arr\n\n# Example usage\nnumbers = [64, 34, 25, 12, 22, 11, 90]\nprint(f\"Original: {numbers}\")\nsorted_numbers = bubble_sort(numbers.copy())\nprint(f\"Sorted: {sorted_numbers}\")\n\n# Python's built-in sorting (much more efficient)\nnumbers.sort()  # In-place sorting\nsorted_list = sorted(numbers)  # Returns new sorted list\n```\n\n**Algorithm Analysis**:\n- Time Complexity: O(n²) worst case, O(n) best case\n- Space Complexity: O(1)\n- Use Python's built-in sort() for production code"}
{"instruction": "How do I work with command line arguments?", "input": "", "output": "Use sys.argv or argparse for command line arguments:\n\n**Using sys.argv (simple):**\n```python\nimport sys\n\n# script.py arg1 arg2\nprint(f\"Script name: {sys.argv[0]}\")\nif len(sys.argv) > 1:\n    print(f\"Arguments: {sys.argv[1:]}\")\nelse:\n    print(\"No arguments provided\")\n```\n\n**Using argparse (recommended):**\n```python\nimport argparse\n\ndef main():\n    parser = argparse.ArgumentParser(description='Process some files')\n    \n    # Positional arguments\n    parser.add_argument('filename', help='Input filename')\n    \n    # Optional arguments\n    parser.add_argument('-v', '--verbose', action='store_true',\n                       help='Enable verbose output')\n    parser.add_argument('-o', '--output', default='output.txt',\n                       help='Output filename')\n    parser.add_argument('-n', '--number', type=int, default=10,\n                       help='Number of items to process')\n    \n    args = parser.parse_args()\n    \n    print(f\"Processing {args.filename}\")\n    if args.verbose:\n        print(f\"Output will be saved to {args.output}\")\n        print(f\"Processing {args.number} items\")\n\nif __name__ == '__main__':\n    main()\n```\n\n**Usage examples:**\n```bash\npython script.py input.txt\npython script.py input.txt -v -o result.txt -n 20\n```"}
{"instruction": "How do I work with databases using SQLite?", "input": "", "output": "SQLite is built into Python and great for simple databases:\n\n```python\nimport sqlite3\n\n# Connect to database (creates if doesn't exist)\nconn = sqlite3.connect('example.db')\ncursor = conn.cursor()\n\n# Create table\ncursor.execute('''\n    CREATE TABLE IF NOT EXISTS users (\n        id INTEGER PRIMARY KEY,\n        name TEXT NOT NULL,\n        email TEXT UNIQUE,\n        age INTEGER\n    )\n''')\n\n# Insert data\ncursor.execute(\"INSERT INTO users (name, email, age) VALUES (?, ?, ?)\",\n               (\"Alice\", \"alice@example.com\", 30))\n\n# Insert multiple records\nusers_data = [\n    (\"Bob\", \"bob@example.com\", 25),\n    (\"Charlie\", \"charlie@example.com\", 35)\n]\ncursor.executemany(\"INSERT INTO users (name, email, age) VALUES (?, ?, ?)\", users_data)\n\n# Commit changes\nconn.commit()\n\n# Query data\ncursor.execute(\"SELECT * FROM users WHERE age > ?\", (25,))\nresults = cursor.fetchall()\nfor row in results:\n    print(f\"ID: {row[0]}, Name: {row[1]}, Email: {row[2]}, Age: {row[3]}\")\n\n# Update data\ncursor.execute(\"UPDATE users SET age = ? WHERE name = ?\", (31, \"Alice\"))\n\n# Delete data\ncursor.execute(\"DELETE FROM users WHERE age < ?\", (30,))\n\n# Close connection\nconn.close()\n```\n\n**Best Practices**:\n- Always use parameterized queries (?) to prevent SQL injection\n- Use context managers or ensure connections are closed\n- Commit transactions explicitly"}
{"instruction": "How do I implement a linked list in Python?", "input": "", "output": "A linked list is a linear data structure where elements are stored in nodes:\n\n```python\nclass Node:\n    def __init__(self, data):\n        self.data = data\n        self.next = None\n\nclass LinkedList:\n    def __init__(self):\n        self.head = None\n    \n    def append(self, data):\n        new_node = Node(data)\n        if not self.head:\n            self.head = new_node\n            return\n        current = self.head\n        while current.next:\n            current = current.next\n        current.next = new_node\n    \n    def prepend(self, data):\n        new_node = Node(data)\n        new_node.next = self.head\n        self.head = new_node\n    \n    def delete(self, data):\n        if not self.head:\n            return\n        \n        if self.head.data == data:\n            self.head = self.head.next\n            return\n        \n        current = self.head\n        while current.next:\n            if current.next.data == data:\n                current.next = current.next.next\n                return\n            current = current.next\n    \n    def display(self):\n        elements = []\n        current = self.head\n        while current:\n            elements.append(current.data)\n            current = current.next\n        return elements\n    \n    def find(self, data):\n        current = self.head\n        while current:\n            if current.data == data:\n                return True\n            current = current.next\n        return False\n\n# Example usage\nll = LinkedList()\nll.append(1)\nll.append(2)\nll.append(3)\nll.prepend(0)\nprint(ll.display())  # [0, 1, 2, 3]\nll.delete(2)\nprint(ll.display())  # [0, 1, 3]\nprint(ll.find(1))    # True\n```"}
{"instruction": "How do I use context managers in Python?", "input": "", "output": "Context managers ensure proper resource management:\n\n**Built-in context managers:**\n```python\n# File handling\nwith open('file.txt', 'r') as f:\n    content = f.read()\n# File automatically closed\n\n# Thread locks\nimport threading\nlock = threading.Lock()\nwith lock:\n    # Critical section\n    shared_resource += 1\n```\n\n**Creating custom context managers:**\n```python\nclass DatabaseConnection:\n    def __enter__(self):\n        print(\"Opening database connection\")\n        # Setup code here\n        return self\n    \n    def __exit__(self, exc_type, exc_val, exc_tb):\n        print(\"Closing database connection\")\n        # Cleanup code here\n        return False  # Don't suppress exceptions\n    \n    def query(self, sql):\n        return f\"Executing: {sql}\"\n\n# Usage\nwith DatabaseConnection() as db:\n    result = db.query(\"SELECT * FROM users\")\n    print(result)\n\n# Using contextlib\nfrom contextlib import contextmanager\n\n@contextmanager\ndef timer():\n    import time\n    start = time.time()\n    try:\n        yield\n    finally:\n        end = time.time()\n        print(f\"Elapsed time: {end - start:.2f} seconds\")\n\n# Usage\nwith timer():\n    # Some time-consuming operation\n    time.sleep(1)\n```\n\n**Benefits**:\n- Guaranteed cleanup even if exceptions occur\n- Cleaner, more readable code\n- Automatic resource management"}
{"instruction": "How do I work with APIs using requests?", "input": "", "output": "The requests library makes HTTP API calls simple:\n\n```python\nimport requests\nimport json\n\n# GET request\nresponse = requests.get('https://jsonplaceholder.typicode.com/posts/1')\nprint(f\"Status Code: {response.status_code}\")\nprint(f\"JSON Data: {response.json()}\")\n\n# GET with parameters\nparams = {'userId': 1}\nresponse = requests.get('https://jsonplaceholder.typicode.com/posts', params=params)\nposts = response.json()\nprint(f\"Found {len(posts)} posts\")\n\n# POST request\nnew_post = {\n    'title': 'My New Post',\n    'body': 'This is the content',\n    'userId': 1\n}\nresponse = requests.post('https://jsonplaceholder.typicode.com/posts', json=new_post)\nprint(f\"Created post: {response.json()}\")\n\n# Headers and authentication\nheaders = {\n    'Authorization': 'Bearer your-token-here',\n    'User-Agent': 'My Python App'\n}\nresponse = requests.get('https://api.example.com/data', headers=headers)\n\n# Error handling\ntry:\n    response = requests.get('https://httpbin.org/status/404', timeout=5)\n    response.raise_for_status()  # Raises exception for HTTP errors\nexcept requests.exceptions.HTTPError as e:\n    print(f\"HTTP error: {e}\")\nexcept requests.exceptions.Timeout:\n    print(\"Request timed out\")\nexcept requests.exceptions.RequestException as e:\n    print(f\"Request failed: {e}\")\n\n# Session for multiple requests\nsession = requests.Session()\nsession.headers.update({'User-Agent': 'My App'})\nresponse1 = session.get('https://httpbin.org/get')\nresponse2 = session.get('https://httpbin.org/user-agent')\n```\n\n**Best Practices**:\n- Always handle exceptions and timeouts\n- Use sessions for multiple requests to same host\n- Set appropriate timeouts\n- Check status codes before processing response"}
{"instruction": "How do I implement a stack data structure?", "input": "", "output": "A stack follows Last-In-First-Out (LIFO) principle:\n\n```python\nclass Stack:\n    def __init__(self):\n        self.items = []\n    \n    def push(self, item):\n        \"\"\"Add item to top of stack\"\"\"\n        self.items.append(item)\n    \n    def pop(self):\n        \"\"\"Remove and return top item\"\"\"\n        if self.is_empty():\n            raise IndexError(\"pop from empty stack\")\n        return self.items.pop()\n    \n    def peek(self):\n        \"\"\"Return top item without removing\"\"\"\n        if self.is_empty():\n            raise IndexError(\"peek from empty stack\")\n        return self.items[-1]\n    \n    def is_empty(self):\n        \"\"\"Check if stack is empty\"\"\"\n        return len(self.items) == 0\n    \n    def size(self):\n        \"\"\"Return number of items\"\"\"\n        return len(self.items)\n    \n    def __str__(self):\n        return f\"Stack({self.items})\"\n\n# Example usage\nstack = Stack()\nstack.push(1)\nstack.push(2)\nstack.push(3)\nprint(stack)  # Stack([1, 2, 3])\nprint(f\"Top item: {stack.peek()}\")  # Top item: 3\nprint(f\"Popped: {stack.pop()}\")     # Popped: 3\nprint(f\"Size: {stack.size()}\")      # Size: 2\n\n# Practical example: Balanced parentheses checker\ndef is_balanced(expression):\n    stack = Stack()\n    pairs = {'(': ')', '[': ']', '{': '}'}\n    \n    for char in expression:\n        if char in pairs:  # Opening bracket\n            stack.push(char)\n        elif char in pairs.values():  # Closing bracket\n            if stack.is_empty():\n                return False\n            if pairs[stack.pop()] != char:\n                return False\n    \n    return stack.is_empty()\n\nprint(is_balanced(\"([{}])\"))  # True\nprint(is_balanced(\"([)]\"))   # False\n```\n\n**Applications**:\n- Function call management\n- Undo operations\n- Expression evaluation\n- Browser back/forward functionality"}
{"instruction": "How do I work with threading in Python?", "input": "", "output": "Threading allows concurrent execution of code:\n\n```python\nimport threading\nimport time\n\n# Basic thread creation\ndef worker(name):\n    for i in range(5):\n        print(f\"Worker {name}: {i}\")\n        time.sleep(1)\n\n# Create and start threads\nthread1 = threading.Thread(target=worker, args=(\"A\",))\nthread2 = threading.Thread(target=worker, args=(\"B\",))\n\nthread1.start()\nthread2.start()\n\n# Wait for threads to complete\nthread1.join()\nthread2.join()\nprint(\"All threads completed\")\n\n# Thread synchronization with locks\nshared_counter = 0\nlock = threading.Lock()\n\ndef increment_counter():\n    global shared_counter\n    for _ in range(100000):\n        with lock:  # Acquire lock\n            shared_counter += 1\n        # Lock automatically released\n\nthreads = []\nfor i in range(5):\n    t = threading.Thread(target=increment_counter)\n    threads.append(t)\n    t.start()\n\nfor t in threads:\n    t.join()\n\nprint(f\"Final counter value: {shared_counter}\")\n\n# Thread-safe queue\nfrom queue import Queue\n\ndef producer(q):\n    for i in range(5):\n        item = f\"item_{i}\"\n        q.put(item)\n        print(f\"Produced: {item}\")\n        time.sleep(0.5)\n\ndef consumer(q):\n    while True:\n        item = q.get()\n        if item is None:\n            break\n        print(f\"Consumed: {item}\")\n        q.task_done()\n        time.sleep(1)\n\nqueue = Queue()\nproducer_thread = threading.Thread(target=producer, args=(queue,))\nconsumer_thread = threading.Thread(target=consumer, args=(queue,))\n\nproducer_thread.start()\nconsumer_thread.start()\n\nproducer_thread.join()\nqueue.put(None)  # Signal consumer to stop\nconsumer_thread.join()\n```\n\n**Important Notes**:\n- Python's GIL (Global Interpreter Lock) limits true parallelism\n- Use threading for I/O-bound tasks\n- Use multiprocessing for CPU-bound tasks\n- Always use locks for shared resources"}
{"instruction": "How do I work with environment variables?", "input": "", "output": "Environment variables store configuration outside your code:\n\n```python\nimport os\nfrom dotenv import load_dotenv  # pip install python-dotenv\n\n# Reading environment variables\napi_key = os.environ.get('API_KEY')\nif not api_key:\n    raise ValueError(\"API_KEY environment variable not set\")\n\n# With default value\ndebug_mode = os.environ.get('DEBUG', 'False').lower() == 'true'\nport = int(os.environ.get('PORT', '8000'))\n\nprint(f\"API Key: {api_key}\")\nprint(f\"Debug mode: {debug_mode}\")\nprint(f\"Port: {port}\")\n\n# Setting environment variables (current session only)\nos.environ['TEMP_VAR'] = 'temporary_value'\nprint(os.environ.get('TEMP_VAR'))\n\n# Using .env files (recommended for development)\n# Create a .env file:\n# API_KEY=your_secret_key_here\n# DEBUG=True\n# DATABASE_URL=postgresql://user:pass@localhost/db\n\nload_dotenv()  # Load variables from .env file\n\napi_key = os.environ.get('API_KEY')\ndatabase_url = os.environ.get('DATABASE_URL')\n\n# Configuration class pattern\nclass Config:\n    def __init__(self):\n        self.api_key = os.environ.get('API_KEY')\n        self.debug = os.environ.get('DEBUG', 'False').lower() == 'true'\n        self.database_url = os.environ.get('DATABASE_URL')\n        self.secret_key = os.environ.get('SECRET_KEY')\n        \n        # Validate required variables\n        if not self.api_key:\n            raise ValueError(\"API_KEY is required\")\n        if not self.secret_key:\n            raise ValueError(\"SECRET_KEY is required\")\n\nconfig = Config()\n```\n\n**Setting environment variables:**\n```bash\n# Linux/macOS\nexport API_KEY=\"your_key_here\"\nexport DEBUG=\"True\"\n\n# Windows\nset API_KEY=your_key_here\nset DEBUG=True\n\n# Or in .env file (recommended)\nAPI_KEY=your_key_here\nDEBUG=True\n```\n\n**Best Practices**:\n- Never commit secrets to version control\n- Use .env files for development\n- Validate required environment variables at startup\n- Use different .env files for different environments"}
{"instruction": "How do I implement error handling with custom exceptions?", "input": "", "output": "Create custom exceptions for specific error conditions:\n\n```python\n# Define custom exceptions\nclass ValidationError(Exception):\n    \"\"\"Raised when input validation fails\"\"\"\n    def __init__(self, message, field=None):\n        self.message = message\n        self.field = field\n        super().__init__(self.message)\n\nclass DatabaseError(Exception):\n    \"\"\"Raised when database operations fail\"\"\"\n    def __init__(self, message, error_code=None):\n        self.message = message\n        self.error_code = error_code\n        super().__init__(self.message)\n\nclass AuthenticationError(Exception):\n    \"\"\"Raised when authentication fails\"\"\"\n    pass\n\n# Example usage in a class\nclass User:\n    def __init__(self, username, email, age):\n        self.username = self.validate_username(username)\n        self.email = self.validate_email(email)\n        self.age = self.validate_age(age)\n    \n    def validate_username(self, username):\n        if not username or len(username) < 3:\n            raise ValidationError(\"Username must be at least 3 characters\", \"username\")\n        if not username.isalnum():\n            raise ValidationError(\"Username must contain only letters and numbers\", \"username\")\n        return username\n    \n    def validate_email(self, email):\n        if '@' not in email or '.' not in email:\n            raise ValidationError(\"Invalid email format\", \"email\")\n        return email\n    \n    def validate_age(self, age):\n        if not isinstance(age, int) or age < 0 or age > 150:\n            raise ValidationError(\"Age must be between 0 and 150\", \"age\")\n        return age\n\n# Function that uses custom exceptions\ndef authenticate_user(username, password):\n    # Simulate authentication logic\n    if not username or not password:\n        raise AuthenticationError(\"Username and password are required\")\n    \n    if username != \"admin\" or password != \"secret\":\n        raise AuthenticationError(\"Invalid credentials\")\n    \n    return {\"username\": username, \"role\": \"admin\"}\n\n# Exception handling with multiple custom exceptions\ndef create_user_account(username, email, age, password):\n    try:\n        # Validate user data\n        user = User(username, email, age)\n        \n        # Authenticate (for demo purposes)\n        auth_data = authenticate_user(username, password)\n        \n        # Simulate database save\n        if username == \"duplicate\":\n            raise DatabaseError(\"Username already exists\", error_code=\"DUPLICATE_KEY\")\n        \n        return {\"user\": user, \"auth\": auth_data}\n        \n    except ValidationError as e:\n        print(f\"Validation Error in {e.field}: {e.message}\")\n        return None\n    except AuthenticationError as e:\n        print(f\"Authentication Error: {e}\")\n        return None\n    except DatabaseError as e:\n        print(f\"Database Error ({e.error_code}): {e.message}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error: {e}\")\n        return None\n\n# Test the error handling\ntest_cases = [\n    (\"ab\", \"valid@email.com\", 25, \"secret\"),  # Username too short\n    (\"validuser\", \"invalid-email\", 25, \"secret\"),  # Invalid email\n    (\"validuser\", \"valid@email.com\", -5, \"secret\"),  # Invalid age\n    (\"validuser\", \"valid@email.com\", 25, \"wrong\"),  # Wrong password\n    (\"duplicate\", \"valid@email.com\", 25, \"secret\"),  # Duplicate username\n    (\"admin\", \"valid@email.com\", 25, \"secret\"),  # Valid case\n]\n\nfor username, email, age, password in test_cases:\n    print(f\"\\nTesting: {username}, {email}, {age}\")\n    result = create_user_account(username, email, age, password)\n    if result:\n        print(\"✓ User created successfully\")\n```\n\n**Best Practices**:\n- Create specific exception classes for different error types\n- Include relevant context in exception messages\n- Use exception hierarchies for related errors\n- Handle exceptions at the appropriate level\n- Log exceptions for debugging"}
{"instruction": "How do I work with pathlib for file operations?", "input": "", "output": "Pathlib provides an object-oriented approach to file paths:\n\n```python\nfrom pathlib import Path\nimport shutil\n\n# Creating Path objects\ncurrent_dir = Path('.')\nhome_dir = Path.home()\nfile_path = Path('data') / 'files' / 'document.txt'\nprint(f\"File path: {file_path}\")\n\n# Path properties\npath = Path('/home/user/documents/report.pdf')\nprint(f\"Name: {path.name}\")          # report.pdf\nprint(f\"Stem: {path.stem}\")          # report\nprint(f\"Suffix: {path.suffix}\")      # .pdf\nprint(f\"Parent: {path.parent}\")      # /home/user/documents\nprint(f\"Parts: {path.parts}\")        # ('/', 'home', 'user', 'documents', 'report.pdf')\n\n# Creating directories\ndata_dir = Path('data')\ndata_dir.mkdir(exist_ok=True)  # Create if doesn't exist\n\nsubdir = Path('data/processed/output')\nsubdir.mkdir(parents=True, exist_ok=True)  # Create parent dirs too\n\n# File operations\nfile_path = Path('data/sample.txt')\n\n# Writing to file\nfile_path.write_text('Hello, World!\\nThis is a test file.')\n\n# Reading from file\ncontent = file_path.read_text()\nprint(f\"File content: {content}\")\n\n# File information\nif file_path.exists():\n    print(f\"File size: {file_path.stat().st_size} bytes\")\n    print(f\"Is file: {file_path.is_file()}\")\n    print(f\"Is directory: {file_path.is_dir()}\")\n\n# Iterating through directories\nfor item in current_dir.iterdir():\n    if item.is_file():\n        print(f\"File: {item.name}\")\n    elif item.is_dir():\n        print(f\"Directory: {item.name}\")\n\n# Finding files with patterns\npy_files = list(current_dir.glob('*.py'))\nprint(f\"Python files: {[f.name for f in py_files]}\")\n\n# Recursive search\nall_txt_files = list(current_dir.rglob('*.txt'))\nprint(f\"All .txt files: {[f.name for f in all_txt_files]}\")\n\n# File operations\nsource = Path('data/sample.txt')\ndestination = Path('data/backup.txt')\n\n# Copy file\nshutil.copy2(source, destination)\n\n# Move/rename file\nold_path = Path('data/backup.txt')\nnew_path = Path('data/sample_backup.txt')\nold_path.rename(new_path)\n\n# Delete file\nif new_path.exists():\n    new_path.unlink()  # Delete file\n\n# Working with different operating systems\nfrom pathlib import PurePosixPath, PureWindowsPath\n\n# Always use forward slashes\nposix_path = PurePosixPath('data/files/document.txt')\nprint(posix_path)  # data/files/document.txt\n\n# Convert to Windows path\nwindows_path = PureWindowsPath(posix_path)\nprint(windows_path)  # data\\files\\document.txt\n\n# Path joining (platform independent)\nbase_path = Path('project')\nfull_path = base_path / 'src' / 'modules' / 'main.py'\nprint(full_path)  # Uses correct separator for current OS\n```\n\n**Benefits over os.path**:\n- More intuitive and readable\n- Object-oriented interface\n- Platform independent\n- Built-in file operations\n- Better error handling"}
{"instruction": "How do I work with async/await in Python?", "input": "", "output": "Async/await enables asynchronous programming for I/O-bound tasks:\n\n```python\nimport asyncio\nimport aiohttp\nimport time\n\n# Basic async function\nasync def say_hello(name, delay):\n    await asyncio.sleep(delay)\n    print(f\"Hello, {name}!\")\n\n# Running async functions\nasync def main():\n    # Run sequentially\n    await say_hello(\"Alice\", 1)\n    await say_hello(\"Bob\", 1)\n    \n    # Run concurrently\n    await asyncio.gather(\n        say_hello(\"Charlie\", 1),\n        say_hello(\"David\", 1)\n    )\n\n# Execute the async function\nasyncio.run(main())\n\n# Async HTTP requests\nasync def fetch_url(session, url):\n    try:\n        async with session.get(url) as response:\n            return await response.text()\n    except Exception as e:\n        return f\"Error: {e}\"\n\nasync def fetch_multiple_urls():\n    urls = [\n        'https://httpbin.org/delay/1',\n        'https://httpbin.org/delay/2',\n        'https://httpbin.org/delay/1'\n    ]\n    \n    async with aiohttp.ClientSession() as session:\n        # Fetch all URLs concurrently\n        tasks = [fetch_url(session, url) for url in urls]\n        results = await asyncio.gather(*tasks)\n        return results\n\n# Async generators\nasync def async_generator():\n    for i in range(5):\n        await asyncio.sleep(0.5)\n        yield i\n\nasync def consume_async_generator():\n    async for value in async_generator():\n        print(f\"Generated: {value}\")\n\n# Async context managers\nclass AsyncContextManager:\n    async def __aenter__(self):\n        print(\"Entering async context\")\n        await asyncio.sleep(0.1)\n        return self\n    \n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        print(\"Exiting async context\")\n        await asyncio.sleep(0.1)\n\nasync def use_async_context():\n    async with AsyncContextManager() as ctx:\n        print(\"Inside context\")\n        await asyncio.sleep(0.5)\n```\n\n**Key Concepts**:\n- Use `async def` for coroutines\n- Use `await` for awaitable objects\n- `asyncio.run()` to start async programs\n- `asyncio.gather()` for concurrent execution"}
{"instruction": "How do I implement a queue data structure?", "input": "", "output": "A queue follows First-In-First-Out (FIFO) principle:\n\n```python\nfrom collections import deque\n\nclass Queue:\n    def __init__(self):\n        self.items = deque()\n    \n    def enqueue(self, item):\n        \"\"\"Add item to rear of queue\"\"\"\n        self.items.append(item)\n    \n    def dequeue(self):\n        \"\"\"Remove and return front item\"\"\"\n        if self.is_empty():\n            raise IndexError(\"dequeue from empty queue\")\n        return self.items.popleft()\n    \n    def front(self):\n        \"\"\"Return front item without removing\"\"\"\n        if self.is_empty():\n            raise IndexError(\"front from empty queue\")\n        return self.items[0]\n    \n    def is_empty(self):\n        \"\"\"Check if queue is empty\"\"\"\n        return len(self.items) == 0\n    \n    def size(self):\n        \"\"\"Return number of items\"\"\"\n        return len(self.items)\n    \n    def __str__(self):\n        return f\"Queue({list(self.items)})\"\n\n# Example usage\nqueue = Queue()\nqueue.enqueue(\"First\")\nqueue.enqueue(\"Second\")\nqueue.enqueue(\"Third\")\nprint(queue)  # Queue(['First', 'Second', 'Third'])\n\nprint(f\"Front: {queue.front()}\")  # Front: First\nprint(f\"Dequeued: {queue.dequeue()}\")  # Dequeued: First\nprint(f\"Size: {queue.size()}\")  # Size: 2\n\n# Priority Queue example\nimport heapq\n\nclass PriorityQueue:\n    def __init__(self):\n        self.items = []\n        self.counter = 0\n    \n    def enqueue(self, item, priority):\n        # Use counter to break ties and maintain FIFO for same priority\n        heapq.heappush(self.items, (priority, self.counter, item))\n        self.counter += 1\n    \n    def dequeue(self):\n        if not self.items:\n            raise IndexError(\"dequeue from empty priority queue\")\n        priority, count, item = heapq.heappop(self.items)\n        return item\n    \n    def is_empty(self):\n        return len(self.items) == 0\n\n# Priority queue usage\npq = PriorityQueue()\npq.enqueue(\"Low priority task\", 3)\npq.enqueue(\"High priority task\", 1)\npq.enqueue(\"Medium priority task\", 2)\n\nwhile not pq.is_empty():\n    print(pq.dequeue())\n# Output: High priority task, Medium priority task, Low priority task\n\n# Using Python's built-in queue module\nfrom queue import Queue as ThreadSafeQueue\nfrom queue import PriorityQueue as ThreadSafePriorityQueue\n\n# Thread-safe queue for multi-threading\nthread_queue = ThreadSafeQueue()\nthread_queue.put(\"item1\")\nthread_queue.put(\"item2\")\nitem = thread_queue.get()  # Returns \"item1\"\n```\n\n**Applications**:\n- Task scheduling\n- Breadth-first search\n- Buffer for producer-consumer problems\n- Print job management"}
{"instruction": "How do I work with numpy arrays?", "input": "", "output": "NumPy provides powerful array operations for numerical computing:\n\n```python\nimport numpy as np\n\n# Creating arrays\narr1d = np.array([1, 2, 3, 4, 5])\narr2d = np.array([[1, 2, 3], [4, 5, 6]])\nzeros = np.zeros((3, 4))  # 3x4 array of zeros\nones = np.ones((2, 3))   # 2x3 array of ones\nrange_arr = np.arange(0, 10, 2)  # [0, 2, 4, 6, 8]\nlinspace = np.linspace(0, 1, 5)  # [0, 0.25, 0.5, 0.75, 1]\nrandom_arr = np.random.random((3, 3))  # 3x3 random array\n\n# Array properties\nprint(f\"Shape: {arr2d.shape}\")      # (2, 3)\nprint(f\"Size: {arr2d.size}\")        # 6\nprint(f\"Dtype: {arr2d.dtype}\")      # int64\nprint(f\"Dimensions: {arr2d.ndim}\")  # 2\n\n# Array indexing and slicing\narr = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\nprint(arr[2:5])    # [2 3 4]\nprint(arr[::2])    # [0 2 4 6 8] - every 2nd element\nprint(arr[-3:])    # [7 8 9] - last 3 elements\n\n# 2D array indexing\narr2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nprint(arr2d[1, 2])     # 6 - row 1, column 2\nprint(arr2d[0, :])     # [1 2 3] - first row\nprint(arr2d[:, 1])     # [2 5 8] - second column\nprint(arr2d[1:, :2])   # [[4 5], [7 8]] - subarray\n\n# Array operations\na = np.array([1, 2, 3, 4])\nb = np.array([5, 6, 7, 8])\n\n# Element-wise operations\nprint(a + b)      # [6 8 10 12] - addition\nprint(a * b)      # [5 12 21 32] - multiplication\nprint(a ** 2)     # [1 4 9 16] - power\nprint(np.sqrt(a)) # [1. 1.41... 1.73... 2.] - square root\n\n# Matrix operations\nmatrix1 = np.array([[1, 2], [3, 4]])\nmatrix2 = np.array([[5, 6], [7, 8]])\nprint(np.dot(matrix1, matrix2))  # Matrix multiplication\nprint(matrix1 @ matrix2)         # Alternative syntax\n\n# Statistical operations\ndata = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\nprint(f\"Mean: {np.mean(data)}\")      # 5.5\nprint(f\"Median: {np.median(data)}\")  # 5.5\nprint(f\"Std: {np.std(data)}\")        # 2.87...\nprint(f\"Min: {np.min(data)}\")        # 1\nprint(f\"Max: {np.max(data)}\")        # 10\nprint(f\"Sum: {np.sum(data)}\")        # 55\n\n# Boolean indexing\narr = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\nmask = arr > 5\nprint(arr[mask])  # [6 7 8 9 10] - elements > 5\nprint(arr[arr % 2 == 0])  # [2 4 6 8 10] - even numbers\n\n# Array reshaping\narr = np.arange(12)\nreshaped = arr.reshape(3, 4)  # 3x4 array\nflattened = reshaped.flatten()  # Back to 1D\ntransposed = reshaped.T  # Transpose\n\n# Concatenating arrays\na = np.array([1, 2, 3])\nb = np.array([4, 5, 6])\nconcat = np.concatenate([a, b])  # [1 2 3 4 5 6]\nvstack = np.vstack([a, b])       # [[1 2 3], [4 5 6]]\nhstack = np.hstack([a, b])       # [1 2 3 4 5 6]\n```\n\n**Key Benefits**:\n- Much faster than Python lists for numerical operations\n- Vectorized operations\n- Broadcasting for operations on different-shaped arrays\n- Extensive mathematical functions\n- Memory efficient"}
{"instruction": "How do I work with pandas DataFrames?", "input": "", "output": "Pandas provides powerful data manipulation and analysis tools:\n\n```python\nimport pandas as pd\nimport numpy as np\n\n# Creating DataFrames\ndata = {\n    'Name': ['Alice', 'Bob', 'Charlie', 'Diana'],\n    'Age': [25, 30, 35, 28],\n    'City': ['New York', 'London', 'Tokyo', 'Paris'],\n    'Salary': [50000, 60000, 70000, 55000]\n}\ndf = pd.DataFrame(data)\n\n# From lists\ndf2 = pd.DataFrame([\n    ['Alice', 25, 'New York'],\n    ['Bob', 30, 'London']\n], columns=['Name', 'Age', 'City'])\n\n# Basic DataFrame info\nprint(df.head(2))      # First 2 rows\nprint(df.tail(2))      # Last 2 rows\nprint(df.info())       # Data types and non-null counts\nprint(df.describe())   # Statistical summary\nprint(df.shape)        # (rows, columns)\n\n# Selecting data\nprint(df['Name'])           # Single column\nprint(df[['Name', 'Age']])  # Multiple columns\nprint(df.iloc[0])           # First row by position\nprint(df.loc[0, 'Name'])    # Specific cell\nprint(df.iloc[0:2, 1:3])    # Slice by position\n\n# Filtering data\nyoung_people = df[df['Age'] < 30]\nhigh_earners = df[df['Salary'] > 55000]\ncombined_filter = df[(df['Age'] < 35) & (df['Salary'] > 50000)]\nprint(young_people)\n\n# Adding and modifying columns\ndf['Bonus'] = df['Salary'] * 0.1  # New column\ndf['Age_Group'] = df['Age'].apply(lambda x: 'Young' if x < 30 else 'Adult')\ndf.loc[df['City'] == 'Tokyo', 'Salary'] = 75000  # Conditional update\n\n# Dropping columns and rows\ndf_dropped = df.drop('Bonus', axis=1)  # Drop column\ndf_dropped = df.drop(0, axis=0)        # Drop row\n\n# Sorting\ndf_sorted = df.sort_values('Age')                    # Sort by age\ndf_multi_sort = df.sort_values(['City', 'Age'])     # Multi-column sort\ndf_desc = df.sort_values('Salary', ascending=False) # Descending\n\n# Grouping and aggregation\nby_city = df.groupby('City')['Salary'].mean()\nby_age_group = df.groupby('Age_Group').agg({\n    'Salary': ['mean', 'max', 'min'],\n    'Age': 'count'\n})\n\n# Handling missing data\ndf_with_nan = df.copy()\ndf_with_nan.loc[0, 'Salary'] = np.nan\n\nprint(df_with_nan.isnull().sum())  # Count missing values\ndf_filled = df_with_nan.fillna(df_with_nan['Salary'].mean())  # Fill with mean\ndf_dropped_na = df_with_nan.dropna()  # Remove rows with NaN\n\n# String operations\ndf['Name_Upper'] = df['Name'].str.upper()\ndf['Name_Length'] = df['Name'].str.len()\nfiltered_names = df[df['Name'].str.contains('A')]\n\n# Merging DataFrames\ndf_additional = pd.DataFrame({\n    'Name': ['Alice', 'Bob', 'Eve'],\n    'Department': ['Engineering', 'Sales', 'Marketing']\n})\nmerged = pd.merge(df, df_additional, on='Name', how='left')\n\n# Reading and writing files\n# df.to_csv('employees.csv', index=False)\n# df_from_csv = pd.read_csv('employees.csv')\n# df.to_excel('employees.xlsx', index=False)\n# df_from_excel = pd.read_excel('employees.xlsx')\n\n# Date/time operations\ndate_data = pd.DataFrame({\n    'date': pd.date_range('2023-01-01', periods=10, freq='D'),\n    'value': np.random.randn(10)\n})\ndate_data['year'] = date_data['date'].dt.year\ndate_data['month'] = date_data['date'].dt.month\ndate_data['weekday'] = date_data['date'].dt.day_name()\n\n# Pivot tables\npivot = df.pivot_table(\n    values='Salary',\n    index='Age_Group',\n    columns='City',\n    aggfunc='mean'\n)\n\nprint(\"\\nPivot Table:\")\nprint(pivot)\n```\n\n**Key Features**:\n- Powerful data manipulation and cleaning\n- Easy file I/O (CSV, Excel, JSON, SQL)\n- Flexible grouping and aggregation\n- Time series functionality\n- Seamless integration with other libraries"}
{"instruction": "How do I implement unit testing with pytest?", "input": "", "output": "Pytest is a powerful testing framework for Python:\n\n```python\n# test_calculator.py\nimport pytest\nfrom calculator import Calculator  # Assuming we have a calculator module\n\nclass TestCalculator:\n    def setup_method(self):\n        \"\"\"Setup before each test method\"\"\"\n        self.calc = Calculator()\n    \n    def test_addition(self):\n        \"\"\"Test basic addition\"\"\"\n        assert self.calc.add(2, 3) == 5\n        assert self.calc.add(-1, 1) == 0\n        assert self.calc.add(0, 0) == 0\n    \n    def test_subtraction(self):\n        \"\"\"Test basic subtraction\"\"\"\n        assert self.calc.subtract(5, 3) == 2\n        assert self.calc.subtract(0, 5) == -5\n    \n    def test_multiplication(self):\n        \"\"\"Test multiplication\"\"\"\n        assert self.calc.multiply(3, 4) == 12\n        assert self.calc.multiply(-2, 3) == -6\n        assert self.calc.multiply(0, 5) == 0\n    \n    def test_division(self):\n        \"\"\"Test division\"\"\"\n        assert self.calc.divide(10, 2) == 5\n        assert self.calc.divide(7, 2) == 3.5\n    \n    def test_division_by_zero(self):\n        \"\"\"Test division by zero raises exception\"\"\"\n        with pytest.raises(ZeroDivisionError):\n            self.calc.divide(10, 0)\n    \n    def test_invalid_input(self):\n        \"\"\"Test invalid input handling\"\"\"\n        with pytest.raises(TypeError):\n            self.calc.add(\"2\", 3)\n\n# Parametrized tests\n@pytest.mark.parametrize(\"a,b,expected\", [\n    (2, 3, 5),\n    (0, 0, 0),\n    (-1, 1, 0),\n    (10, -5, 5)\n])\ndef test_addition_parametrized(a, b, expected):\n    calc = Calculator()\n    assert calc.add(a, b) == expected\n\n# Fixtures for reusable test data\n@pytest.fixture\ndef sample_data():\n    \"\"\"Provide sample data for tests\"\"\"\n    return [1, 2, 3, 4, 5]\n\n@pytest.fixture\ndef temp_file(tmp_path):\n    \"\"\"Create a temporary file for testing\"\"\"\n    file_path = tmp_path / \"test_file.txt\"\n    file_path.write_text(\"Hello, World!\")\n    return file_path\n\ndef test_with_fixture(sample_data):\n    \"\"\"Test using a fixture\"\"\"\n    assert len(sample_data) == 5\n    assert sum(sample_data) == 15\n\ndef test_file_operations(temp_file):\n    \"\"\"Test file operations with temporary file\"\"\"\n    content = temp_file.read_text()\n    assert content == \"Hello, World!\"\n    assert temp_file.exists()\n\n# Mocking with pytest-mock\ndef test_api_call(mocker):\n    \"\"\"Test API call with mocking\"\"\"\n    # Mock the requests.get function\n    mock_get = mocker.patch('requests.get')\n    mock_get.return_value.json.return_value = {'status': 'success'}\n    mock_get.return_value.status_code = 200\n    \n    # Your function that makes API call\n    result = make_api_call('https://api.example.com')\n    \n    assert result['status'] == 'success'\n    mock_get.assert_called_once_with('https://api.example.com')\n\n# Skip tests conditionally\n@pytest.mark.skip(reason=\"Feature not implemented yet\")\ndef test_future_feature():\n    \"\"\"This test will be skipped\"\"\"\n    pass\n\n@pytest.mark.skipif(sys.version_info < (3, 8), reason=\"Requires Python 3.8+\")\ndef test_python38_feature():\n    \"\"\"Skip if Python version is too old\"\"\"\n    pass\n\n# Marking tests for selective running\n@pytest.mark.slow\ndef test_slow_operation():\n    \"\"\"Mark as slow test\"\"\"\n    import time\n    time.sleep(2)\n    assert True\n\n@pytest.mark.integration\ndef test_database_integration():\n    \"\"\"Mark as integration test\"\"\"\n    # Test that requires database\n    pass\n\n# Custom markers (define in pytest.ini or pyproject.toml)\n@pytest.mark.unit\ndef test_unit_logic():\n    \"\"\"Unit test marker\"\"\"\n    assert 1 + 1 == 2\n\n# Testing exceptions with more detail\ndef test_custom_exception():\n    \"\"\"Test custom exception details\"\"\"\n    with pytest.raises(ValueError) as exc_info:\n        raise_custom_error(\"invalid input\")\n    \n    assert \"invalid input\" in str(exc_info.value)\n    assert exc_info.type == ValueError\n\n# Approximate comparisons for floats\ndef test_float_comparison():\n    \"\"\"Test floating point comparisons\"\"\"\n    result = 0.1 + 0.2\n    assert result == pytest.approx(0.3)\n    assert result == pytest.approx(0.3, rel=1e-9)\n\n# Setup and teardown for test class\nclass TestDatabaseOperations:\n    @classmethod\n    def setup_class(cls):\n        \"\"\"Setup once for entire class\"\"\"\n        cls.db = setup_test_database()\n    \n    @classmethod\n    def teardown_class(cls):\n        \"\"\"Cleanup after all tests in class\"\"\"\n        cls.db.close()\n    \n    def test_create_user(self):\n        user = self.db.create_user(\"test@example.com\")\n        assert user.email == \"test@example.com\"\n    \n    def test_delete_user(self):\n        user = self.db.create_user(\"delete@example.com\")\n        self.db.delete_user(user.id)\n        assert self.db.get_user(user.id) is None\n```\n\n**Running tests:**\n```bash\n# Run all tests\npytest\n\n# Run specific test file\npytest test_calculator.py\n\n# Run tests with verbose output\npytest -v\n\n# Run only tests matching pattern\npytest -k \"addition\"\n\n# Run tests with specific marker\npytest -m \"unit\"\n\n# Generate coverage report\npytest --cov=calculator\n\n# Run tests in parallel\npytest -n auto\n```\n\n**Best Practices**:\n- Use descriptive test names\n- Test edge cases and error conditions\n- Use fixtures for setup and teardown\n- Parametrize tests for multiple inputs\n- Mock external dependencies\n- Aim for high test coverage but focus on critical paths"}
{"instruction": "How do I implement recursion in Python?", "input": "", "output": "Recursion is when a function calls itself to solve a smaller version of the problem:\n\n```python\n# Basic recursion example: factorial\ndef factorial(n):\n    # Base case\n    if n <= 1:\n        return 1\n    # Recursive case\n    return n * factorial(n - 1)\n\nprint(factorial(5))  # 120\n\n# Fibonacci sequence\ndef fibonacci(n):\n    if n <= 1:\n        return n\n    return fibonacci(n - 1) + fibonacci(n - 2)\n\nprint(fibonacci(6))  # 8\n\n# Tree traversal\ndef print_tree(node, depth=0):\n    if node is None:\n        return\n    \n    print('  ' * depth + str(node.value))\n    print_tree(node.left, depth + 1)\n    print_tree(node.right, depth + 1)\n\n# Tail recursion example\ndef countdown(n):\n    if n <= 0:\n        print('Done!')\n        return\n    \n    print(n)\n    countdown(n - 1)\n\ncountdown(5)\n```\n\n**Key Points**:\n- Always have a base case to stop recursion\n- Each recursive call should work on a smaller problem\n- Watch out for stack overflow with deep recursion\n- Consider iterative solutions for better performance"}
{"instruction": "How do I work with lambda functions?", "input": "", "output": "Lambda functions are small anonymous functions defined with the lambda keyword:\n\n```python\n# Basic lambda function\nsquare = lambda x: x ** 2\nprint(square(5))  # 25\n\n# Lambda with multiple arguments\nadd = lambda x, y: x + y\nprint(add(3, 4))  # 7\n\n# Using lambda with built-in functions\nnumbers = [1, 2, 3, 4, 5]\n\n# With map()\nsquared = list(map(lambda x: x ** 2, numbers))\nprint(squared)  # [1, 4, 9, 16, 25]\n\n# With filter()\neven = list(filter(lambda x: x % 2 == 0, numbers))\nprint(even)  # [2, 4]\n\n# With sorted()\nstudents = [('Alice', 85), ('Bob', 90), ('Charlie', 78)]\nsorted_by_grade = sorted(students, key=lambda x: x[1])\nprint(sorted_by_grade)  # [('Charlie', 78), ('Alice', 85), ('Bob', 90)]\n\n# Lambda in list comprehensions (alternative)\nsquared_comp = [x ** 2 for x in numbers]  # Preferred over lambda\n\n# Complex lambda example\ndata = [{'name': 'Alice', 'age': 30}, {'name': 'Bob', 'age': 25}]\nsorted_data = sorted(data, key=lambda person: person['age'])\nprint(sorted_data)\n```\n\n**Best Practices**:\n- Use lambda for simple, one-line functions\n- Prefer regular functions for complex logic\n- List comprehensions often better than map/filter with lambda\n- Don't assign lambda to variables (use def instead)"}
{"instruction": "How do I work with multiprocessing in Python?", "input": "", "output": "Multiprocessing enables true parallelism by using separate processes:\n\n```python\nimport multiprocessing\nimport time\nimport os\n\n# Basic multiprocessing\ndef worker_function(name, duration):\n    print(f\"Worker {name} starting on process {os.getpid()}\")\n    time.sleep(duration)\n    print(f\"Worker {name} finished\")\n    return f\"Result from {name}\"\n\n# Using Process class\nif __name__ == '__main__':\n    # Create processes\n    process1 = multiprocessing.Process(target=worker_function, args=(\"A\", 2))\n    process2 = multiprocessing.Process(target=worker_function, args=(\"B\", 3))\n    \n    # Start processes\n    process1.start()\n    process2.start()\n    \n    # Wait for completion\n    process1.join()\n    process2.join()\n    \n    print(\"All processes completed\")\n\n# Using Pool for multiple workers\ndef cpu_intensive_task(n):\n    \"\"\"Simulate CPU-intensive work\"\"\"\n    result = 0\n    for i in range(n * 1000000):\n        result += i * i\n    return result\n\nif __name__ == '__main__':\n    # Using Pool\n    with multiprocessing.Pool(processes=4) as pool:\n        tasks = [10, 20, 30, 40, 50]\n        results = pool.map(cpu_intensive_task, tasks)\n        print(f\"Results: {results}\")\n\n# Process communication with Queue\ndef producer(queue, items):\n    for item in items:\n        queue.put(item)\n        print(f\"Produced: {item}\")\n        time.sleep(0.5)\n    queue.put(None)  # Signal completion\n\ndef consumer(queue):\n    while True:\n        item = queue.get()\n        if item is None:\n            break\n        print(f\"Consumed: {item}\")\n        time.sleep(1)\n\nif __name__ == '__main__':\n    # Create queue\n    queue = multiprocessing.Queue()\n    \n    # Create processes\n    producer_process = multiprocessing.Process(\n        target=producer, args=(queue, ['item1', 'item2', 'item3'])\n    )\n    consumer_process = multiprocessing.Process(target=consumer, args=(queue,))\n    \n    # Start processes\n    producer_process.start()\n    consumer_process.start()\n    \n    # Wait for completion\n    producer_process.join()\n    consumer_process.join()\n\n# Shared memory example\ndef increment_shared_value(shared_var, lock, name):\n    for i in range(5):\n        with lock:\n            temp = shared_var.value\n            temp += 1\n            shared_var.value = temp\n            print(f\"{name}: {shared_var.value}\")\n        time.sleep(0.1)\n\nif __name__ == '__main__':\n    # Create shared variable and lock\n    shared_var = multiprocessing.Value('i', 0)  # 'i' for integer\n    lock = multiprocessing.Lock()\n    \n    # Create processes\n    processes = []\n    for i in range(3):\n        p = multiprocessing.Process(\n            target=increment_shared_value,\n            args=(shared_var, lock, f\"Process-{i}\")\n        )\n        processes.append(p)\n        p.start()\n    \n    # Wait for all processes\n    for p in processes:\n        p.join()\n    \n    print(f\"Final value: {shared_var.value}\")\n\n# Async multiprocessing with ProcessPoolExecutor\nfrom concurrent.futures import ProcessPoolExecutor\nimport concurrent.futures\n\ndef process_data(data):\n    # Simulate processing\n    result = sum(x * x for x in data)\n    return result\n\nif __name__ == '__main__':\n    data_chunks = [\n        [1, 2, 3, 4, 5],\n        [6, 7, 8, 9, 10],\n        [11, 12, 13, 14, 15]\n    ]\n    \n    with ProcessPoolExecutor(max_workers=4) as executor:\n        # Submit tasks\n        futures = [executor.submit(process_data, chunk) for chunk in data_chunks]\n        \n        # Get results as they complete\n        for future in concurrent.futures.as_completed(futures):\n            result = future.result()\n            print(f\"Chunk result: {result}\")\n```\n\n**Key Differences from Threading**:\n- True parallelism (no GIL limitation)\n- Higher memory overhead\n- Better for CPU-intensive tasks\n- Communication through queues/pipes\n- Separate memory spaces"}
{"instruction": "How do I create a simple web server with Flask?", "input": "", "output": "Flask is a lightweight web framework for Python:\n\n```python\nfrom flask import Flask, request, jsonify, render_template, redirect, url_for\nfrom flask import session, flash\nimport os\n\n# Create Flask app\napp = Flask(__name__)\napp.secret_key = 'your-secret-key-here'  # Change this in production\n\n# Sample data\nusers = [\n    {'id': 1, 'name': 'Alice', 'email': 'alice@example.com'},\n    {'id': 2, 'name': 'Bob', 'email': 'bob@example.com'}\n]\n\n# Basic route\n@app.route('/')\ndef home():\n    return '<h1>Welcome to My Flask App!</h1>'\n\n# Route with parameters\n@app.route('/user/<int:user_id>')\ndef get_user(user_id):\n    user = next((u for u in users if u['id'] == user_id), None)\n    if user:\n        return jsonify(user)\n    return jsonify({'error': 'User not found'}), 404\n\n# Route with multiple HTTP methods\n@app.route('/api/users', methods=['GET', 'POST'])\ndef handle_users():\n    if request.method == 'GET':\n        return jsonify(users)\n    \n    elif request.method == 'POST':\n        data = request.get_json()\n        if not data or 'name' not in data or 'email' not in data:\n            return jsonify({'error': 'Name and email required'}), 400\n        \n        new_id = max(u['id'] for u in users) + 1 if users else 1\n        new_user = {\n            'id': new_id,\n            'name': data['name'],\n            'email': data['email']\n        }\n        users.append(new_user)\n        return jsonify(new_user), 201\n\n# Form handling\n@app.route('/contact', methods=['GET', 'POST'])\ndef contact():\n    if request.method == 'POST':\n        name = request.form.get('name')\n        email = request.form.get('email')\n        message = request.form.get('message')\n        \n        # Process form data (save to database, send email, etc.)\n        flash(f'Thank you {name}! Your message has been received.')\n        return redirect(url_for('contact'))\n    \n    # Return form template for GET request\n    return '''\n    <form method=\"POST\">\n        <p>Name: <input type=\"text\" name=\"name\" required></p>\n        <p>Email: <input type=\"email\" name=\"email\" required></p>\n        <p>Message: <textarea name=\"message\" required></textarea></p>\n        <p><input type=\"submit\" value=\"Send\"></p>\n    </form>\n    '''\n\n# Session handling\n@app.route('/login', methods=['GET', 'POST'])\ndef login():\n    if request.method == 'POST':\n        username = request.form.get('username')\n        password = request.form.get('password')\n        \n        # Simple authentication (use proper auth in production)\n        if username == 'admin' and password == 'secret':\n            session['username'] = username\n            flash('Login successful!')\n            return redirect(url_for('dashboard'))\n        else:\n            flash('Invalid credentials!')\n    \n    return '''\n    <form method=\"POST\">\n        <p>Username: <input type=\"text\" name=\"username\"></p>\n        <p>Password: <input type=\"password\" name=\"password\"></p>\n        <p><input type=\"submit\" value=\"Login\"></p>\n    </form>\n    '''\n\n@app.route('/dashboard')\ndef dashboard():\n    if 'username' not in session:\n        return redirect(url_for('login'))\n    return f'<h1>Welcome, {session[\"username\"]}!</h1>'\n\n@app.route('/logout')\ndef logout():\n    session.pop('username', None)\n    flash('You have been logged out.')\n    return redirect(url_for('home'))\n\n# Error handlers\n@app.errorhandler(404)\ndef not_found(error):\n    return jsonify({'error': 'Not found'}), 404\n\n@app.errorhandler(500)\ndef internal_error(error):\n    return jsonify({'error': 'Internal server error'}), 500\n\n# API with request validation\n@app.route('/api/calculate', methods=['POST'])\ndef calculate():\n    try:\n        data = request.get_json()\n        \n        if not data:\n            return jsonify({'error': 'No JSON data provided'}), 400\n        \n        operation = data.get('operation')\n        a = data.get('a')\n        b = data.get('b')\n        \n        if None in [operation, a, b]:\n            return jsonify({'error': 'Missing required fields'}), 400\n        \n        if not isinstance(a, (int, float)) or not isinstance(b, (int, float)):\n            return jsonify({'error': 'a and b must be numbers'}), 400\n        \n        if operation == 'add':\n            result = a + b\n        elif operation == 'subtract':\n            result = a - b\n        elif operation == 'multiply':\n            result = a * b\n        elif operation == 'divide':\n            if b == 0:\n                return jsonify({'error': 'Division by zero'}), 400\n            result = a / b\n        else:\n            return jsonify({'error': 'Invalid operation'}), 400\n        \n        return jsonify({\n            'operation': operation,\n            'a': a,\n            'b': b,\n            'result': result\n        })\n    \n    except Exception as e:\n        return jsonify({'error': str(e)}), 500\n\n# File upload\n@app.route('/upload', methods=['GET', 'POST'])\ndef upload_file():\n    if request.method == 'POST':\n        if 'file' not in request.files:\n            flash('No file selected')\n            return redirect(request.url)\n        \n        file = request.files['file']\n        if file.filename == '':\n            flash('No file selected')\n            return redirect(request.url)\n        \n        if file:\n            filename = file.filename\n            # In production, validate and sanitize filename\n            file.save(os.path.join('uploads', filename))\n            flash(f'File {filename} uploaded successfully!')\n            return redirect(url_for('upload_file'))\n    \n    return '''\n    <form method=\"POST\" enctype=\"multipart/form-data\">\n        <p>File: <input type=\"file\" name=\"file\"></p>\n        <p><input type=\"submit\" value=\"Upload\"></p>\n    </form>\n    '''\n\n# Configuration\nclass Config:\n    SECRET_KEY = os.environ.get('SECRET_KEY') or 'dev-secret-key'\n    DEBUG = os.environ.get('FLASK_DEBUG', 'False').lower() == 'true'\n\napp.config.from_object(Config)\n\n# Run the app\nif __name__ == '__main__':\n    # Create uploads directory\n    os.makedirs('uploads', exist_ok=True)\n    \n    # Run in debug mode\n    app.run(debug=True, host='0.0.0.0', port=5000)\n```\n\n**Key Features**:\n- Routing and URL parameters\n- HTTP methods (GET, POST, etc.)\n- Request handling (JSON, forms, files)\n- Session management\n- Error handling\n- Template rendering (with Jinja2)\n\n**Installation**:\n```bash\npip install flask\n```"}
{"instruction": "How do I work with regular expressions (regex)?", "input": "", "output": "Regular expressions are powerful patterns for text matching and manipulation:\n\n```python\nimport re\n\n# Basic pattern matching\ntext = \"My phone number is 555-123-4567\"\npattern = r'\\d{3}-\\d{3}-\\d{4}'\nmatch = re.search(pattern, text)\nif match:\n    print(f\"Found: {match.group()}\")  # Found: 555-123-4567\n\n# Common regex patterns\nemail_pattern = r'[\\w.-]+@[\\w.-]+\\.\\w+'\nphone_pattern = r'\\(?\\d{3}\\)?[-\\s]?\\d{3}[-\\s]?\\d{4}'\nurl_pattern = r'https?://[\\w.-]+(?:/[\\w.-]*)*'\ndate_pattern = r'\\d{4}-\\d{2}-\\d{2}'\n\n# Find all matches\nemail_text = \"Contact: john@example.com or jane@test.org\"\nemails = re.findall(email_pattern, email_text)\nprint(emails)  # ['john@example.com', 'jane@test.org']\n\n# Replace patterns\ntext = \"Hello world! This is a test.\"\nresult = re.sub(r'world', 'Python', text)\nprint(result)  # \"Hello Python! This is a test.\"\n\n# Case-insensitive replacement\nresult = re.sub(r'HELLO', 'Hi', text, flags=re.IGNORECASE)\nprint(result)  # \"Hi world! This is a test.\"\n\n# Using groups for extraction\ndate_text = \"Today is 2023-12-25 and tomorrow is 2023-12-26\"\ndate_pattern = r'(\\d{4})-(\\d{2})-(\\d{2})'\nmatches = re.finditer(date_pattern, date_text)\n\nfor match in matches:\n    year, month, day = match.groups()\n    print(f\"Date: {match.group()}, Year: {year}, Month: {month}, Day: {day}\")\n\n# Named groups\nlog_pattern = r'(?P<timestamp>\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}) (?P<level>\\w+) (?P<message>.*)'\nlog_line = \"2023-12-25 10:30:45 ERROR Database connection failed\"\nmatch = re.search(log_pattern, log_line)\n\nif match:\n    print(f\"Timestamp: {match.group('timestamp')}\")\n    print(f\"Level: {match.group('level')}\")\n    print(f\"Message: {match.group('message')}\")\n\n# Validation functions\ndef validate_email(email):\n    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n    return re.match(pattern, email) is not None\n\ndef validate_password(password):\n    # At least 8 chars, 1 uppercase, 1 lowercase, 1 digit, 1 special char\n    pattern = r'^(?=.*[a-z])(?=.*[A-Z])(?=.*\\d)(?=.*[@$!%*?&])[A-Za-z\\d@$!%*?&]{8,}$'\n    return re.match(pattern, password) is not None\n\ndef validate_phone(phone):\n    # US phone number format\n    pattern = r'^\\(?([0-9]{3})\\)?[-. ]?([0-9]{3})[-. ]?([0-9]{4})$'\n    return re.match(pattern, phone) is not None\n\n# Test validations\nprint(validate_email(\"user@example.com\"))  # True\nprint(validate_email(\"invalid-email\"))     # False\nprint(validate_password(\"Password123!\"))   # True\nprint(validate_password(\"weak\"))           # False\n\n# Text processing example\ndef extract_urls(text):\n    url_pattern = r'https?://(?:[-\\w.])+(?:[:\\d]+)?(?:/(?:[\\w/_.])*(?:\\?(?:[\\w&=%.])*)?(?:#(?:\\w*))?)?'\n    return re.findall(url_pattern, text)\n\ndef clean_html_tags(text):\n    \"\"\"Remove HTML tags from text\"\"\"\n    clean = re.compile('<.*?>')\n    return re.sub(clean, '', text)\n\ndef extract_hashtags(text):\n    \"\"\"Extract hashtags from social media text\"\"\"\n    hashtag_pattern = r'#\\w+'\n    return re.findall(hashtag_pattern, text)\n\n# Advanced pattern: parsing CSV-like data\ndef parse_csv_line(line):\n    # Handle quoted fields with commas\n    pattern = r'\"([^\"]*)\"|([^,]+)'\n    matches = re.findall(pattern, line)\n    return [match[0] if match[0] else match[1] for match in matches]\n\ncsv_line = 'John,\"Doe, Jr.\",30,\"New York, NY\"'\nfields = parse_csv_line(csv_line)\nprint(fields)  # ['John', 'Doe, Jr.', '30', 'New York, NY']\n\n# Compile patterns for better performance\ncompiled_email = re.compile(r'[\\w.-]+@[\\w.-]+\\.\\w+')\ncompiled_phone = re.compile(r'\\d{3}-\\d{3}-\\d{4}')\n\n# Use compiled patterns\ntext = \"Contact John at john@email.com or call 555-123-4567\"\nemail_match = compiled_email.search(text)\nphone_match = compiled_phone.search(text)\n\nif email_match:\n    print(f\"Email: {email_match.group()}\")\nif phone_match:\n    print(f\"Phone: {phone_match.group()}\")\n\n# Word boundaries and anchors\n# \\b = word boundary, ^ = start of string, $ = end of string\nwhole_word_pattern = r'\\bcat\\b'  # Matches 'cat' but not 'category'\nstart_pattern = r'^Hello'       # Matches lines starting with 'Hello'\nend_pattern = r'world$'         # Matches lines ending with 'world'\n\n# Lookahead and lookbehind\npassword_with_lookahead = r'^(?=.*[A-Z])(?=.*[a-z])(?=.*\\d).{8,}$'\n# Must contain uppercase, lowercase, and digit\n\n# Split text using regex\ntext = \"apple,banana;orange:grape\"\nfruits = re.split(r'[,;:]', text)\nprint(fruits)  # ['apple', 'banana', 'orange', 'grape']\n```\n\n**Common Regex Symbols**:\n- `.` : Any character except newline\n- `*` : Zero or more occurrences\n- `+` : One or more occurrences\n- `?` : Zero or one occurrence\n- `\\d` : Any digit (0-9)\n- `\\w` : Any word character (a-z, A-Z, 0-9, _)\n- `\\s` : Any whitespace character\n- `[]` : Character class\n- `()` : Grouping\n- `|` : OR operator\n\n**Best Practices**:\n- Use raw strings (r'') for regex patterns\n- Compile patterns you'll use multiple times\n- Test regex patterns with online tools\n- Be careful with greedy vs non-greedy matching\n- Escape special characters when needed"}
{"instruction": "How do I work with web scraping using BeautifulSoup?", "input": "", "output": "BeautifulSoup is excellent for parsing HTML and XML documents:\n\n```python\nimport requests\nfrom bs4 import BeautifulSoup\nimport csv\nimport time\n\n# Basic web scraping\ndef scrape_basic_page():\n    url = \"https://httpbin.org/html\"\n    response = requests.get(url)\n    \n    if response.status_code == 200:\n        soup = BeautifulSoup(response.content, 'html.parser')\n        \n        # Find elements by tag\n        title = soup.find('title').text\n        print(f\"Page title: {title}\")\n        \n        # Find all paragraphs\n        paragraphs = soup.find_all('p')\n        for p in paragraphs:\n            print(f\"Paragraph: {p.text}\")\n        \n        # Find by class\n        content = soup.find('div', class_='content')\n        if content:\n            print(f\"Content: {content.text}\")\n        \n        # Find by CSS selector\n        links = soup.select('a[href]')\n        for link in links:\n            print(f\"Link: {link.text} -> {link.get('href')}\")\n    \n    else:\n        print(f\"Failed to fetch page: {response.status_code}\")\n\n# Scraping a table\ndef scrape_table_data(url):\n    \"\"\"Extract table data from webpage\"\"\"\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, 'html.parser')\n    \n    # Find the table\n    table = soup.find('table', class_='data-table')\n    if not table:\n        print(\"No table found\")\n        return []\n    \n    data = []\n    \n    # Extract headers\n    headers = []\n    header_row = table.find('tr')\n    if header_row:\n        for th in header_row.find_all(['th', 'td']):\n            headers.append(th.text.strip())\n    \n    # Extract data rows\n    rows = table.find_all('tr')[1:]  # Skip header row\n    for row in rows:\n        row_data = []\n        cells = row.find_all(['td', 'th'])\n        for cell in cells:\n            row_data.append(cell.text.strip())\n        if row_data:  # Only add non-empty rows\n            data.append(row_data)\n    \n    return headers, data\n\n# Advanced scraping with multiple pages\nclass WebScraper:\n    def __init__(self, base_url, delay=1):\n        self.base_url = base_url\n        self.delay = delay\n        self.session = requests.Session()\n        # Set user agent to avoid blocking\n        self.session.headers.update({\n            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n        })\n    \n    def get_page(self, url):\n        \"\"\"Fetch a single page with error handling\"\"\"\n        try:\n            response = self.session.get(url, timeout=10)\n            response.raise_for_status()\n            return BeautifulSoup(response.content, 'html.parser')\n        except requests.RequestException as e:\n            print(f\"Error fetching {url}: {e}\")\n            return None\n    \n    def scrape_product_listings(self, category_url):\n        \"\"\"Scrape product information from a category page\"\"\"\n        soup = self.get_page(category_url)\n        if not soup:\n            return []\n        \n        products = []\n        \n        # Find product containers\n        product_items = soup.find_all('div', class_='product-item')\n        \n        for item in product_items:\n            product = {}\n            \n            # Extract product name\n            name_elem = item.find('h3', class_='product-name')\n            product['name'] = name_elem.text.strip() if name_elem else 'N/A'\n            \n            # Extract price\n            price_elem = item.find('span', class_='price')\n            if price_elem:\n                price_text = price_elem.text.strip()\n                # Clean price text (remove currency symbols, etc.)\n                price = ''.join(filter(str.isdigit + str.isdecimal + '.'.__contains__, price_text))\n                product['price'] = float(price) if price else 0.0\n            else:\n                product['price'] = 0.0\n            \n            # Extract product URL\n            link_elem = item.find('a', href=True)\n            product['url'] = link_elem['href'] if link_elem else ''\n            \n            # Extract image URL\n            img_elem = item.find('img', src=True)\n            product['image'] = img_elem['src'] if img_elem else ''\n            \n            products.append(product)\n            \n        return products\n    \n    def scrape_with_pagination(self, base_category_url, max_pages=5):\n        \"\"\"Scrape multiple pages with pagination\"\"\"\n        all_products = []\n        \n        for page_num in range(1, max_pages + 1):\n            page_url = f\"{base_category_url}?page={page_num}\"\n            print(f\"Scraping page {page_num}: {page_url}\")\n            \n            products = self.scrape_product_listings(page_url)\n            if not products:\n                print(f\"No products found on page {page_num}, stopping\")\n                break\n            \n            all_products.extend(products)\n            \n            # Be respectful to the server\n            time.sleep(self.delay)\n        \n        return all_products\n    \n    def save_to_csv(self, data, filename):\n        \"\"\"Save scraped data to CSV file\"\"\"\n        if not data:\n            print(\"No data to save\")\n            return\n        \n        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n            fieldnames = data[0].keys()\n            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n            \n            writer.writeheader()\n            for row in data:\n                writer.writerow(row)\n        \n        print(f\"Data saved to {filename}\")\n\n# Handling forms and sessions\ndef scrape_with_login(login_url, username, password, target_url):\n    \"\"\"Scrape pages that require login\"\"\"\n    session = requests.Session()\n    \n    # Get login page\n    login_page = session.get(login_url)\n    soup = BeautifulSoup(login_page.content, 'html.parser')\n    \n    # Find CSRF token if present\n    csrf_token = None\n    csrf_input = soup.find('input', {'name': 'csrf_token'})\n    if csrf_input:\n        csrf_token = csrf_input.get('value')\n    \n    # Prepare login data\n    login_data = {\n        'username': username,\n        'password': password\n    }\n    if csrf_token:\n        login_data['csrf_token'] = csrf_token\n    \n    # Perform login\n    login_response = session.post(login_url, data=login_data)\n    \n    if login_response.status_code == 200:\n        # Now scrape the protected page\n        protected_page = session.get(target_url)\n        soup = BeautifulSoup(protected_page.content, 'html.parser')\n        return soup\n    else:\n        print(\"Login failed\")\n        return None\n\n# Example usage\nif __name__ == \"__main__\":\n    # Basic scraping\n    scrape_basic_page()\n    \n    # Advanced scraping\n    scraper = WebScraper(\"https://example-shop.com\", delay=2)\n    products = scraper.scrape_with_pagination(\n        \"https://example-shop.com/category/electronics\",\n        max_pages=3\n    )\n    \n    if products:\n        scraper.save_to_csv(products, \"scraped_products.csv\")\n        print(f\"Scraped {len(products)} products\")\n```\n\n**Best Practices**:\n- Always check robots.txt before scraping\n- Add delays between requests to be respectful\n- Handle errors gracefully\n- Use sessions for better performance\n- Set appropriate User-Agent headers\n- Respect rate limits and terms of service\n- Consider using scrapy for large-scale scraping\n\n**Installation**:\n```bash\npip install beautifulsoup4 requests lxml\n```"}
{"instruction": "How do I implement binary tree traversal algorithms?", "input": "", "output": "Binary tree traversal algorithms visit nodes in different orders:\n\n```python\nclass TreeNode:\n    def __init__(self, val=0, left=None, right=None):\n        self.val = val\n        self.left = left\n        self.right = right\n    \n    def __str__(self):\n        return str(self.val)\n\nclass BinaryTree:\n    def __init__(self, root=None):\n        self.root = root\n    \n    # Depth-First Search (DFS) Traversals\n    \n    def inorder_recursive(self, root, result=None):\n        \"\"\"Inorder: Left -> Root -> Right\"\"\"\n        if result is None:\n            result = []\n        \n        if root:\n            self.inorder_recursive(root.left, result)\n            result.append(root.val)\n            self.inorder_recursive(root.right, result)\n        \n        return result\n    \n    def preorder_recursive(self, root, result=None):\n        \"\"\"Preorder: Root -> Left -> Right\"\"\"\n        if result is None:\n            result = []\n        \n        if root:\n            result.append(root.val)\n            self.preorder_recursive(root.left, result)\n            self.preorder_recursive(root.right, result)\n        \n        return result\n    \n    def postorder_recursive(self, root, result=None):\n        \"\"\"Postorder: Left -> Right -> Root\"\"\"\n        if result is None:\n            result = []\n        \n        if root:\n            self.postorder_recursive(root.left, result)\n            self.postorder_recursive(root.right, result)\n            result.append(root.val)\n        \n        return result\n    \n    # Iterative DFS traversals using stacks\n    \n    def inorder_iterative(self, root):\n        \"\"\"Iterative inorder traversal\"\"\"\n        result = []\n        stack = []\n        current = root\n        \n        while stack or current:\n            # Go to leftmost node\n            while current:\n                stack.append(current)\n                current = current.left\n            \n            # Process current node\n            current = stack.pop()\n            result.append(current.val)\n            \n            # Move to right subtree\n            current = current.right\n        \n        return result\n    \n    def preorder_iterative(self, root):\n        \"\"\"Iterative preorder traversal\"\"\"\n        if not root:\n            return []\n        \n        result = []\n        stack = [root]\n        \n        while stack:\n            node = stack.pop()\n            result.append(node.val)\n            \n            # Push right first, then left (so left is processed first)\n            if node.right:\n                stack.append(node.right)\n            if node.left:\n                stack.append(node.left)\n        \n        return result\n    \n    def postorder_iterative(self, root):\n        \"\"\"Iterative postorder traversal\"\"\"\n        if not root:\n            return []\n        \n        result = []\n        stack = []\n        last_visited = None\n        current = root\n        \n        while stack or current:\n            if current:\n                stack.append(current)\n                current = current.left\n            else:\n                peek_node = stack[-1]\n                # If right child exists and hasn't been processed yet\n                if peek_node.right and last_visited != peek_node.right:\n                    current = peek_node.right\n                else:\n                    result.append(peek_node.val)\n                    last_visited = stack.pop()\n        \n        return result\n    \n    # Breadth-First Search (BFS) Traversal\n    \n    def level_order(self, root):\n        \"\"\"Level-order traversal (BFS)\"\"\"\n        if not root:\n            return []\n        \n        result = []\n        queue = [root]\n        \n        while queue:\n            node = queue.pop(0)  # Dequeue from front\n            result.append(node.val)\n            \n            # Add children to queue\n            if node.left:\n                queue.append(node.left)\n            if node.right:\n                queue.append(node.right)\n        \n        return result\n    \n    def level_order_by_levels(self, root):\n        \"\"\"Level-order traversal grouped by levels\"\"\"\n        if not root:\n            return []\n        \n        result = []\n        queue = [root]\n        \n        while queue:\n            level_size = len(queue)\n            current_level = []\n            \n            for _ in range(level_size):\n                node = queue.pop(0)\n                current_level.append(node.val)\n                \n                if node.left:\n                    queue.append(node.left)\n                if node.right:\n                    queue.append(node.right)\n            \n            result.append(current_level)\n        \n        return result\n    \n    # Additional tree operations\n    \n    def find_height(self, root):\n        \"\"\"Find height of the tree\"\"\"\n        if not root:\n            return 0\n        \n        left_height = self.find_height(root.left)\n        right_height = self.find_height(root.right)\n        \n        return max(left_height, right_height) + 1\n    \n    def count_nodes(self, root):\n        \"\"\"Count total number of nodes\"\"\"\n        if not root:\n            return 0\n        \n        return 1 + self.count_nodes(root.left) + self.count_nodes(root.right)\n    \n    def find_max(self, root):\n        \"\"\"Find maximum value in the tree\"\"\"\n        if not root:\n            return float('-inf')\n        \n        left_max = self.find_max(root.left)\n        right_max = self.find_max(root.right)\n        \n        return max(root.val, left_max, right_max)\n    \n    def search(self, root, target):\n        \"\"\"Search for a value in the tree\"\"\"\n        if not root:\n            return False\n        \n        if root.val == target:\n            return True\n        \n        return (self.search(root.left, target) or \n                self.search(root.right, target))\n    \n    def print_tree(self, root, level=0, prefix=\"Root: \"):\n        \"\"\"Pretty print the tree structure\"\"\"\n        if root:\n            print(\" \" * (level * 4) + prefix + str(root.val))\n            if root.left or root.right:\n                if root.left:\n                    self.print_tree(root.left, level + 1, \"L--- \")\n                else:\n                    print(\" \" * ((level + 1) * 4) + \"L--- None\")\n                if root.right:\n                    self.print_tree(root.right, level + 1, \"R--- \")\n                else:\n                    print(\" \" * ((level + 1) * 4) + \"R--- None\")\n\n# Example usage and testing\nif __name__ == \"__main__\":\n    # Create a sample binary tree:\n    #       1\n    #      / \\\n    #     2   3\n    #    / \\\n    #   4   5\n    \n    root = TreeNode(1)\n    root.left = TreeNode(2)\n    root.right = TreeNode(3)\n    root.left.left = TreeNode(4)\n    root.left.right = TreeNode(5)\n    \n    tree = BinaryTree(root)\n    \n    print(\"Tree structure:\")\n    tree.print_tree(root)\n    print()\n    \n    # Test all traversal methods\n    print(\"Inorder (Recursive):\", tree.inorder_recursive(root))\n    print(\"Inorder (Iterative):\", tree.inorder_iterative(root))\n    print()\n    \n    print(\"Preorder (Recursive):\", tree.preorder_recursive(root))\n    print(\"Preorder (Iterative):\", tree.preorder_iterative(root))\n    print()\n    \n    print(\"Postorder (Recursive):\", tree.postorder_recursive(root))\n    print(\"Postorder (Iterative):\", tree.postorder_iterative(root))\n    print()\n    \n    print(\"Level Order:\", tree.level_order(root))\n    print(\"Level Order by Levels:\", tree.level_order_by_levels(root))\n    print()\n    \n    # Test additional operations\n    print(f\"Tree height: {tree.find_height(root)}\")\n    print(f\"Total nodes: {tree.count_nodes(root)}\")\n    print(f\"Maximum value: {tree.find_max(root)}\")\n    print(f\"Search for 4: {tree.search(root, 4)}\")\n    print(f\"Search for 6: {tree.search(root, 6)}\")\n```\n\n**Time and Space Complexity**:\n- **Time**: O(n) for all traversals (visit each node once)\n- **Space**: \n  - Recursive: O(h) where h is tree height (call stack)\n  - Iterative: O(h) for DFS, O(w) for BFS where w is max width\n\n**Use Cases**:\n- **Inorder**: BST sorted output, expression evaluation\n- **Preorder**: Tree copying, prefix expression evaluation\n- **Postorder**: Tree deletion, postfix evaluation\n- **Level-order**: Finding shortest path, printing by levels"}
{"instruction": "How do I work with machine learning using scikit-learn?", "input": "", "output": "Scikit-learn provides a comprehensive machine learning library:\n\n```python\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.datasets import make_classification, make_regression, load_iris\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# 1. Classification Example\ndef classification_example():\n    \"\"\"Complete classification workflow\"\"\"\n    print(\"=== Classification Example ===\")\n    \n    # Load sample data\n    iris = load_iris()\n    X, y = iris.data, iris.target\n    \n    # Split the data\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42, stratify=y\n    )\n    \n    # Scale features\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    \n    # Train multiple models\n    models = {\n        'Logistic Regression': LogisticRegression(random_state=42),\n        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n        'SVM': SVC(random_state=42)\n    }\n    \n    results = {}\n    \n    for name, model in models.items():\n        # Train model\n        if name == 'SVM':\n            model.fit(X_train_scaled, y_train)\n            y_pred = model.predict(X_test_scaled)\n        else:\n            model.fit(X_train, y_train)\n            y_pred = model.predict(X_test)\n        \n        # Evaluate\n        accuracy = accuracy_score(y_test, y_pred)\n        results[name] = accuracy\n        \n        print(f\"\\n{name}:\")\n        print(f\"Accuracy: {accuracy:.4f}\")\n        print(\"Classification Report:\")\n        print(classification_report(y_test, y_pred, target_names=iris.target_names))\n    \n    # Cross-validation\n    print(\"\\nCross-validation scores:\")\n    for name, model in models.items():\n        if name == 'SVM':\n            scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n        else:\n            scores = cross_val_score(model, X_train, y_train, cv=5)\n        print(f\"{name}: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n    \n    return results\n\n# 2. Regression Example\ndef regression_example():\n    \"\"\"Complete regression workflow\"\"\"\n    print(\"\\n=== Regression Example ===\")\n    \n    # Generate sample data\n    X, y = make_regression(n_samples=1000, n_features=5, noise=0.1, random_state=42)\n    \n    # Split the data\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n    \n    # Scale features\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    \n    # Train models\n    models = {\n        'Linear Regression': LinearRegression(),\n        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)\n    }\n    \n    for name, model in models.items():\n        # Use scaled data for Linear Regression, original for Random Forest\n        if name == 'Linear Regression':\n            model.fit(X_train_scaled, y_train)\n            y_pred = model.predict(X_test_scaled)\n        else:\n            model.fit(X_train, y_train)\n            y_pred = model.predict(X_test)\n        \n        # Evaluate\n        mse = mean_squared_error(y_test, y_pred)\n        r2 = r2_score(y_test, y_pred)\n        \n        print(f\"\\n{name}:\")\n        print(f\"MSE: {mse:.4f}\")\n        print(f\"R² Score: {r2:.4f}\")\n        \n        # Feature importance for Random Forest\n        if hasattr(model, 'feature_importances_'):\n            importance = model.feature_importances_\n            print(f\"Feature Importances: {importance}\")\n\n# 3. Hyperparameter Tuning\ndef hyperparameter_tuning_example():\n    \"\"\"Hyperparameter tuning with GridSearchCV\"\"\"\n    print(\"\\n=== Hyperparameter Tuning ===\")\n    \n    # Load data\n    iris = load_iris()\n    X, y = iris.data, iris.target\n    \n    # Split data\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n    \n    # Define parameter grid for Random Forest\n    param_grid = {\n        'n_estimators': [50, 100, 200],\n        'max_depth': [3, 5, 7, None],\n        'min_samples_split': [2, 5, 10]\n    }\n    \n    # Grid search\n    rf = RandomForestClassifier(random_state=42)\n    grid_search = GridSearchCV(\n        rf, param_grid, cv=5, scoring='accuracy', n_jobs=-1\n    )\n    \n    grid_search.fit(X_train, y_train)\n    \n    print(f\"Best parameters: {grid_search.best_params_}\")\n    print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n    \n    # Evaluate best model on test set\n    best_model = grid_search.best_estimator_\n    y_pred = best_model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"Test accuracy: {accuracy:.4f}\")\n\n# 4. Data Preprocessing Pipeline\ndef preprocessing_pipeline_example():\n    \"\"\"Complete preprocessing pipeline\"\"\"\n    print(\"\\n=== Data Preprocessing Pipeline ===\")\n    \n    # Create sample data with mixed types\n    data = pd.DataFrame({\n        'numeric1': np.random.randn(1000),\n        'numeric2': np.random.randn(1000) * 10 + 5,\n        'categorical': np.random.choice(['A', 'B', 'C'], 1000),\n        'binary': np.random.choice([0, 1], 1000)\n    })\n    \n    # Add some missing values\n    data.loc[np.random.choice(data.index, 50), 'numeric1'] = np.nan\n    data.loc[np.random.choice(data.index, 30), 'categorical'] = np.nan\n    \n    print(f\"Data shape: {data.shape}\")\n    print(f\"Missing values:\\n{data.isnull().sum()}\")\n    \n    # Handle missing values\n    from sklearn.impute import SimpleImputer\n    \n    # Numeric imputation\n    numeric_imputer = SimpleImputer(strategy='mean')\n    data['numeric1'] = numeric_imputer.fit_transform(data[['numeric1']]).ravel()\n    \n    # Categorical imputation\n    categorical_imputer = SimpleImputer(strategy='most_frequent')\n    data['categorical'] = categorical_imputer.fit_transform(data[['categorical']]).ravel()\n    \n    # Encode categorical variables\n    from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n    \n    # Label encoding for binary\n    le = LabelEncoder()\n    data['categorical_encoded'] = le.fit_transform(data['categorical'])\n    \n    # One-hot encoding\n    ohe = OneHotEncoder(sparse_output=False, drop='first')\n    categorical_encoded = ohe.fit_transform(data[['categorical']])\n    \n    print(f\"\\nAfter preprocessing:\")\n    print(f\"No missing values: {data.isnull().sum().sum() == 0}\")\n    print(f\"Categorical classes: {le.classes_}\")\n    \n    return data\n\n# 5. Model Evaluation and Visualization\ndef model_evaluation_example():\n    \"\"\"Comprehensive model evaluation\"\"\"\n    print(\"\\n=== Model Evaluation ===\")\n    \n    # Generate binary classification data\n    X, y = make_classification(\n        n_samples=1000, n_features=20, n_informative=10,\n        n_redundant=10, n_clusters_per_class=1, random_state=42\n    )\n    \n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n    \n    # Train model\n    model = RandomForestClassifier(n_estimators=100, random_state=42)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    y_pred_proba = model.predict_proba(X_test)[:, 1]\n    \n    # Confusion Matrix\n    cm = confusion_matrix(y_test, y_pred)\n    print(f\"\\nConfusion Matrix:\\n{cm}\")\n    \n    # Classification metrics\n    from sklearn.metrics import precision_score, recall_score, f1_score\n    \n    precision = precision_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred)\n    \n    print(f\"\\nMetrics:\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1-Score: {f1:.4f}\")\n    \n    # ROC AUC\n    from sklearn.metrics import roc_auc_score, roc_curve\n    \n    auc = roc_auc_score(y_test, y_pred_proba)\n    print(f\"ROC AUC: {auc:.4f}\")\n    \n    # Learning curves\n    from sklearn.model_selection import learning_curve\n    \n    train_sizes, train_scores, val_scores = learning_curve(\n        model, X, y, cv=5, n_jobs=-1,\n        train_sizes=np.linspace(0.1, 1.0, 10)\n    )\n    \n    print(f\"\\nLearning curve computed with {len(train_sizes)} points\")\n\n# 6. Feature Selection\ndef feature_selection_example():\n    \"\"\"Feature selection techniques\"\"\"\n    print(\"\\n=== Feature Selection ===\")\n    \n    # Generate data with irrelevant features\n    X, y = make_classification(\n        n_samples=1000, n_features=50, n_informative=10,\n        n_redundant=5, n_clusters_per_class=1, random_state=42\n    )\n    \n    print(f\"Original feature count: {X.shape[1]}\")\n    \n    # Univariate feature selection\n    from sklearn.feature_selection import SelectKBest, f_classif\n    \n    selector = SelectKBest(score_func=f_classif, k=20)\n    X_selected = selector.fit_transform(X, y)\n    \n    print(f\"After SelectKBest: {X_selected.shape[1]}\")\n    \n    # Recursive Feature Elimination\n    from sklearn.feature_selection import RFE\n    \n    estimator = RandomForestClassifier(n_estimators=50, random_state=42)\n    rfe = RFE(estimator, n_features_to_select=15)\n    X_rfe = rfe.fit_transform(X, y)\n    \n    print(f\"After RFE: {X_rfe.shape[1]}\")\n    \n    # Feature importance from tree-based models\n    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n    rf.fit(X, y)\n    \n    # Get feature importance\n    importance = rf.feature_importances_\n    indices = np.argsort(importance)[::-1]\n    \n    print(f\"\\nTop 10 most important features:\")\n    for i in range(10):\n        print(f\"Feature {indices[i]}: {importance[indices[i]]:.4f}\")\n\n# Main execution\nif __name__ == \"__main__\":\n    # Run all examples\n    classification_example()\n    regression_example()\n    hyperparameter_tuning_example()\n    preprocessing_pipeline_example()\n    model_evaluation_example()\n    feature_selection_example()\n    \n    print(\"\\n=== Machine Learning Pipeline Complete ===\")\n```\n\n**Key Concepts**:\n- **Data Preprocessing**: Scaling, encoding, handling missing values\n- **Model Selection**: Different algorithms for different problems\n- **Cross-Validation**: Robust model evaluation\n- **Hyperparameter Tuning**: Optimizing model performance\n- **Feature Selection**: Choosing relevant features\n- **Model Evaluation**: Comprehensive metrics and visualization\n\n**Best Practices**:\n- Always split data before preprocessing\n- Use cross-validation for model selection\n- Scale features for distance-based algorithms\n- Handle missing data appropriately\n- Evaluate models with multiple metrics\n- Consider feature importance and selection"}