{
  "name": "Default LlamaFarm Models Configuration",
  "version": "1.0.0",
  "description": "Default configuration with common providers",
  "default_provider": "openai_gpt4o_mini",
  
  "providers": {
    "openai_gpt4o_mini": {
      "type": "cloud",
      "provider": "openai",
      "model": "gpt-4o-mini",
      "api_key": "${OPENAI_API_KEY}",
      "base_url": "https://api.openai.com/v1",
      "max_tokens": 2048,
      "temperature": 0.7,
      "description": "Fast, cost-effective OpenAI model"
    },
    
    "openai_gpt4_turbo": {
      "type": "cloud",
      "provider": "openai",
      "model": "gpt-4-turbo-preview",
      "api_key": "${OPENAI_API_KEY}",
      "base_url": "https://api.openai.com/v1",
      "max_tokens": 4096,
      "temperature": 0.7,
      "description": "Advanced OpenAI model for complex tasks"
    },
    
    "anthropic_claude_3_haiku": {
      "type": "cloud",
      "provider": "anthropic",
      "model": "claude-3-haiku-20240307",
      "api_key": "${ANTHROPIC_API_KEY}",
      "base_url": "https://api.anthropic.com/v1",
      "max_tokens": 4096,
      "temperature": 0.7,
      "description": "Fast and affordable Claude model"
    },
    
    "ollama_llama3": {
      "type": "local",
      "provider": "ollama",
      "model": "llama3.1:8b",
      "host": "${OLLAMA_HOST:localhost}",
      "port": 11434,
      "timeout": 120,
      "temperature": 0.7,
      "description": "Local Llama 3.1 8B model"
    }
  },
  
  "fallback_chain": ["openai_gpt4o_mini", "anthropic_claude_3_haiku", "ollama_llama3"]
}