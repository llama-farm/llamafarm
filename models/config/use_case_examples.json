{
  "name": "Use Case Specific Model Configurations",
  "version": "1.0.0",
  "description": "Model configurations optimized for specific use cases",
  
  "configurations": {
    "rag_system": {
      "name": "RAG System Configuration",
      "default_provider": "openai_embeddings",
      "providers": {
        "openai_embeddings": {
          "type": "cloud",
          "provider": "openai",
          "model": "text-embedding-3-small",
          "api_key": "${OPENAI_API_KEY}",
          "dimensions": 1536,
          "cost_per_1k_tokens": 0.00002,
          "description": "For document embeddings"
        },
        "openai_rag_query": {
          "type": "cloud",
          "provider": "openai",
          "model": "gpt-4o-mini",
          "api_key": "${OPENAI_API_KEY}",
          "temperature": 0.3,
          "max_tokens": 2048,
          "system_prompt": "You are a helpful assistant. Answer based on the provided context. If the answer is not in the context, say so.",
          "description": "For RAG query responses"
        },
        "ollama_embeddings": {
          "type": "local",
          "provider": "ollama",
          "model": "nomic-embed-text:latest",
          "host": "localhost",
          "port": 11434,
          "description": "Local embeddings fallback"
        }
      }
    },
    
    "code_assistant": {
      "name": "Code Assistant Configuration",
      "default_provider": "openai_code",
      "providers": {
        "openai_code": {
          "type": "cloud",
          "provider": "openai",
          "model": "gpt-4-turbo-preview",
          "api_key": "${OPENAI_API_KEY}",
          "temperature": 0.2,
          "max_tokens": 4096,
          "system_prompt": "You are an expert programmer. Provide clean, efficient, and well-documented code.",
          "description": "Primary code generation"
        },
        "anthropic_code": {
          "type": "cloud",
          "provider": "anthropic",
          "model": "claude-3-opus-20240229",
          "api_key": "${ANTHROPIC_API_KEY}",
          "temperature": 0.2,
          "max_tokens": 4096,
          "system_prompt": "You are Claude, an AI assistant created by Anthropic to be helpful, harmless, and honest. You excel at programming tasks.",
          "description": "Alternative for complex code"
        },
        "ollama_code": {
          "type": "local",
          "provider": "ollama",
          "model": "codellama:13b",
          "temperature": 0.1,
          "timeout": 180,
          "description": "Local code generation"
        }
      }
    },
    
    "customer_support": {
      "name": "Customer Support Configuration",
      "default_provider": "support_primary",
      "fallback_chain": ["support_primary", "support_fallback", "support_local"],
      "providers": {
        "support_primary": {
          "type": "cloud",
          "provider": "openai",
          "model": "gpt-4o-mini",
          "api_key": "${OPENAI_API_KEY}",
          "temperature": 0.7,
          "max_tokens": 1024,
          "system_prompt": "You are a friendly and helpful customer support agent. Be empathetic, professional, and solution-oriented.",
          "description": "Primary support model"
        },
        "support_fallback": {
          "type": "cloud",
          "provider": "anthropic",
          "model": "claude-3-haiku-20240307",
          "api_key": "${ANTHROPIC_API_KEY}",
          "temperature": 0.7,
          "max_tokens": 1024,
          "description": "Fallback support model"
        },
        "support_local": {
          "type": "local",
          "provider": "ollama",
          "model": "llama3.1:8b",
          "temperature": 0.7,
          "system_prompt": "You are a helpful customer support assistant.",
          "description": "Emergency local fallback"
        }
      }
    },
    
    "content_generation": {
      "name": "Content Generation Configuration",
      "default_provider": "content_creative",
      "providers": {
        "content_creative": {
          "type": "cloud",
          "provider": "anthropic",
          "model": "claude-3-sonnet-20240229",
          "api_key": "${ANTHROPIC_API_KEY}",
          "temperature": 0.9,
          "max_tokens": 4096,
          "system_prompt": "You are a creative writer. Generate engaging, original content.",
          "description": "Creative content generation"
        },
        "content_factual": {
          "type": "cloud",
          "provider": "openai",
          "model": "gpt-4-turbo-preview",
          "api_key": "${OPENAI_API_KEY}",
          "temperature": 0.3,
          "max_tokens": 4096,
          "system_prompt": "You are a factual writer. Provide accurate, well-researched content.",
          "description": "Factual content generation"
        },
        "content_seo": {
          "type": "cloud",
          "provider": "cohere",
          "model": "command-r-plus",
          "api_key": "${COHERE_API_KEY}",
          "temperature": 0.7,
          "max_tokens": 2048,
          "system_prompt": "Generate SEO-optimized content with relevant keywords.",
          "description": "SEO-focused content"
        }
      }
    },
    
    "data_analysis": {
      "name": "Data Analysis Configuration",
      "default_provider": "analysis_primary",
      "providers": {
        "analysis_primary": {
          "type": "cloud",
          "provider": "openai",
          "model": "gpt-4-turbo-preview",
          "api_key": "${OPENAI_API_KEY}",
          "temperature": 0.2,
          "max_tokens": 4096,
          "system_prompt": "You are a data analyst. Provide precise analysis with clear insights and recommendations.",
          "response_format": {"type": "json_object"},
          "description": "Primary analysis model"
        },
        "analysis_fast": {
          "type": "cloud",
          "provider": "groq",
          "model": "mixtral-8x7b-32768",
          "api_key": "${GROQ_API_KEY}",
          "temperature": 0.2,
          "max_tokens": 32768,
          "description": "Fast analysis for large datasets"
        },
        "analysis_local": {
          "type": "local",
          "provider": "ollama",
          "model": "llama3.1:8b",
          "temperature": 0.2,
          "system_prompt": "Analyze the provided data and give insights.",
          "description": "Local analysis option"
        }
      }
    },
    
    "translation": {
      "name": "Translation Configuration",
      "default_provider": "translation_primary",
      "providers": {
        "translation_primary": {
          "type": "cloud",
          "provider": "openai",
          "model": "gpt-4o-mini",
          "api_key": "${OPENAI_API_KEY}",
          "temperature": 0.3,
          "max_tokens": 2048,
          "system_prompt": "You are a professional translator. Maintain the tone and context while ensuring accurate translation.",
          "description": "Primary translation model"
        },
        "translation_nuanced": {
          "type": "cloud",
          "provider": "anthropic",
          "model": "claude-3-sonnet-20240229",
          "api_key": "${ANTHROPIC_API_KEY}",
          "temperature": 0.3,
          "max_tokens": 2048,
          "description": "For nuanced translations"
        }
      }
    },
    
    "education": {
      "name": "Educational Assistant Configuration",
      "default_provider": "edu_primary",
      "providers": {
        "edu_primary": {
          "type": "cloud",
          "provider": "openai",
          "model": "gpt-4o-mini",
          "api_key": "${OPENAI_API_KEY}",
          "temperature": 0.5,
          "max_tokens": 2048,
          "system_prompt": "You are an educational assistant. Explain concepts clearly, use examples, and adapt to the student's level.",
          "description": "Primary educational model"
        },
        "edu_socratic": {
          "type": "cloud",
          "provider": "anthropic",
          "model": "claude-3-haiku-20240307",
          "api_key": "${ANTHROPIC_API_KEY}",
          "temperature": 0.7,
          "max_tokens": 1024,
          "system_prompt": "Use the Socratic method. Ask guiding questions to help students discover answers themselves.",
          "description": "Socratic teaching method"
        },
        "edu_local": {
          "type": "local",
          "provider": "ollama",
          "model": "phi3:mini",
          "temperature": 0.5,
          "system_prompt": "Help students learn by explaining concepts simply.",
          "description": "Fast local educational assistant"
        }
      }
    }
  },
  
  "deployment_examples": {
    "development": {
      "preferred_providers": ["ollama_llama3_2", "ollama_phi3", "hf_distilgpt2"],
      "notes": "Use local models to save costs during development"
    },
    "staging": {
      "preferred_providers": ["openai_gpt4o_mini", "anthropic_claude_3_haiku", "ollama_llama3_1"],
      "notes": "Mix of cloud and local for testing"
    },
    "production": {
      "preferred_providers": ["openai_gpt4_turbo", "anthropic_claude_3_sonnet", "groq_llama3_70b"],
      "fallback_chain": ["primary", "secondary", "emergency_local"],
      "notes": "High-quality models with fallback options"
    }
  }
}