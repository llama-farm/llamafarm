[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "llamafarm-models"
version = "0.1.0"
description = "LlamaFarm Models System - Cloud and Local Model Management"
readme = "README.md"
requires-python = ">=3.10"
license = {text = "MIT"}
authors = [
    {name = "LlamaFarm Team", email = "team@llamafarm.dev"},
]
keywords = ["rag", "llm", "models", "openai", "anthropic", "ollama"]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
]

dependencies = [
    "openai>=1.0.0",
    "anthropic>=0.18.0",
    "together>=1.0.0",
    "httpx>=0.25.0",
    "pydantic>=2.0.0",
    "python-dotenv>=1.0.0",
    "requests>=2.31.0",
    "aiohttp>=3.9.0",
    "tenacity>=8.2.0",
    "tiktoken>=0.5.0",
    "colorama>=0.4.6",
    "rich>=13.0.0",
    "click>=8.1.0",
    "jsonschema>=4.20.0",
    "PyYAML>=6.0",
    "huggingface-hub>=0.19.0",
    "transformers>=4.35.0,<4.46.0", # LlamaFactory needs <4.46.0 for LlamaFlashAttention2
    "torch>=2.0.0",
    "accelerate>=0.20.0",
    "datasets>=2.0.0",
    "peft>=0.17.0",
    "safetensors>=0.4.0",
    "psutil>=5.9.0",
    "llamafactory>=0.8.3",
    # Dependencies for GGUF conversion
    "mistral-common>=1.8.0",
    "sentencepiece>=0.2.0",
    "protobuf>=4.25.0",
    "numpy<2.0.0",  # Compatibility with other packages
    "jsonref>=1.1.0",
    # Image recognition dependencies
    "ultralytics>=8.0.0",  # YOLO models for object detection/segmentation
    "opencv-python>=4.8.0",  # Computer vision and image processing
    "opencv-contrib-python>=4.8.0",  # Additional OpenCV modules
    "pillow>=10.0.0",  # Python Imaging Library
    "matplotlib>=3.7.0",  # Plotting and visualization
    "seaborn>=0.12.0",  # Statistical data visualization
    "scikit-image>=0.21.0",  # Image processing algorithms
    "albumentations>=1.3.0",  # Image augmentation library
    "torchvision>=0.15.0",  # PyTorch vision utilities
    "timm>=0.9.0",  # PyTorch image models
    "supervision>=0.16.0",  # Computer vision tools
    "lapx>=0.5.0",  # Linear assignment problem solver
    "tqdm>=4.66.0",  # Progress bars
    "pandas>=2.0.0",  # Data manipulation
    "scipy>=1.10.0",  # Scientific computing
]

[project.optional-dependencies]
image-advanced = [
    # Advanced image models (future additions)
    # Note: Some packages may need manual installation
    "clip-interrogator>=0.6.0",  # CLIP interrogator
    "transformers>=4.35.0",  # For vision transformers
]
image-optimization = [
    # Platform-specific optimizations
    "coremltools>=7.0",  # CoreML for Apple Silicon
    "onnxruntime>=1.16.0",  # ONNX Runtime
    "onnx>=1.14.0",  # ONNX format
    "openvino>=2023.2.0",  # Intel OpenVINO
    "tflite-runtime>=2.14.0",  # TensorFlow Lite
]
image-gpu-nvidia = [
    # NVIDIA-specific (Linux/Windows only - install manually on those platforms)
    # "tensorrt>=8.6.0",  # TensorRT optimization (Linux/Windows only)
    # "pycuda>=2022.2",  # CUDA bindings (requires CUDA toolkit)
    # "cupy>=12.0.0",  # CUDA arrays (requires CUDA toolkit)
]
image-tracking = [
    # Object tracking and video processing
    "norfair>=2.2.0",  # Object tracking
    "filterpy>=1.4.5",  # Kalman filters
    "motpy>=0.0.10",  # Multi-object tracking
]
image-ocr = [
    # OCR and document processing
    "pytesseract>=0.3.10",  # Tesseract OCR
    "easyocr>=1.7.0",  # Easy OCR
    "paddleocr>=2.7.0",  # PaddleOCR
    "pdf2image>=1.16.0",  # PDF to image conversion
    "pymupdf>=1.23.0",  # PDF processing
]
dev = [
    "pytest>=7.4.0",
    "pytest-cov>=4.1.0",
    "pytest-asyncio>=0.21.0",
    "pytest-mock>=3.11.0",
    "black>=23.0.0",
    "isort>=5.12.0",
    "mypy>=1.5.0",
    "ruff>=0.1.0",
    "pre-commit>=3.5.0",
]
vllm = [
    "vllm>=0.2.0",
]
tgi = [
    "text-generation>=0.6.0",
]
finetuning = [
    # Core fine-tuning dependencies (already in main dependencies)
    # Added here for explicit installation: uv add llamafarm-models[finetuning]  
    "torch>=2.0.0",
    "transformers>=4.35.0", 
    "peft>=0.17.0",
    "datasets>=2.0.0",
    "accelerate>=0.20.0",
    "safetensors>=0.4.0",
    # Additional fine-tuning specific tools
    "tensorboard>=2.14.0",
    "wandb>=0.15.0",
]

[project.scripts]
llamafarm = "cli:main"
llamafarm-models = "cli:main"
llamafarm-image = "cli_image_extension:main"

[tool.hatch.build.targets.wheel]
packages = ["."]

[tool.uv]
dev-dependencies = [
    "ipdb>=0.13.13",
    "ipython>=8.20.0",
    "pytest>=8.4.1",
    "pytest-cov>=6.2.1",
]

[tool.pytest.ini_options]
minversion = "7.0"
testpaths = ["tests"]
pythonpath = ["."]
markers = [
    "integration: marks tests as integration tests (deselect with '-m \"not integration\"')",
]
addopts = [
    "-ra",
    "--strict-markers",
]

[tool.black]
line-length = 100
target-version = ['py310', 'py311']

[tool.isort]
profile = "black"
line_length = 100
known_first_party = ["models"]
skip_gitignore = true
