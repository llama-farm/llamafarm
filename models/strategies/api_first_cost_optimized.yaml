# API-First Cost-Optimized Strategy
# Perfect for prototyping and budget-conscious development with cloud APIs
version: "v1"

# Strategy metadata
strategy_info:
  name: "api_first_cost_optimized"
  description: "Cost-optimized cloud API strategy with intelligent model routing"
  use_case: "Prototyping, low-volume apps, budget-conscious development"
  difficulty: "easy"
  cost_level: "low"
  deployment_type: "cloud_api"
  fallback_strategy: "api_primary → api_fallback → local_backup"
  
# Environment-specific configurations for API usage
environments:
  
  # Development Environment - Cost-optimized API usage
  development:
    active: true
    model:
      base_model: "gpt-4o-mini"      # Primary cost-effective model
      model_type: "OpenAIModel"
      api_key: "${OPENAI_API_KEY}"
      fallback_models: ["claude-3-haiku", "groq-llama3-8b"]
      cost_per_1k_input: 0.15
      cost_per_1k_output: 0.60
      
    training:
      method: "api_calls"            # No local training, API-only
      max_tokens: 1000
      temperature: 0.7
      daily_budget: 2.0              # $2/day development limit
      enable_caching: true
      cache_ttl: 3600
      
    generation:
      temperature: 0.7
      max_tokens: 1000
      top_p: 0.9
      stream: true                   # Faster perceived response
      timeout: 30
      
  # Production Environment - Balanced cost and performance
  production:
    active: false
    model:
      base_model: "gpt-4o-mini"
      model_type: "OpenAIModel"
      api_key: "${OPENAI_API_KEY}"
      fallback_models: ["gpt-4o", "claude-3-sonnet"]
      cost_per_1k_input: 0.15
      cost_per_1k_output: 0.60
      
    training:
      method: "api_calls"
      max_tokens: 2000
      temperature: 0.7
      daily_budget: 10.0             # $10/day production limit
      enable_caching: true
      cache_ttl: 1800
      enable_monitoring: true
      
    generation:
      temperature: 0.7
      max_tokens: 2000
      top_p: 0.9
      stream: true
      timeout: 45
      
  # Local Fallback - Emergency backup when APIs fail
  local_fallback:
    active: false
    model:
      base_model: "phi3:mini"
      model_type: "Ollama"
      device: "auto"
      ollama_model: "phi3:mini"
      download_if_missing: true
      
    training:
      method: "inference_only"       # No training, just inference
      
    generation:
      temperature: 0.8
      max_tokens: 512
      top_p: 0.9

# Dataset configuration for prompt engineering
dataset:
  path: "datasets/api_prompts.jsonl"
  format: "jsonl"
  text_column: "prompt"
  prompt_template: |
    {instruction}
  max_length: 1000
  validation_split: 0.1

# API performance evaluation
evaluation:
  metrics:
    - "cost_per_request"
    - "response_time"
    - "success_rate"
    - "quality_score"
  eval_dataset: "validation"
  custom_metrics:
    cost_efficiency:
      cost_threshold: 0.05          # Alert if cost > $0.05 per request
      quality_threshold: 0.8        # Maintain quality > 80%
  
# Output configuration
output:
  model_name: "api-cost-optimized"
  save_directory: "./models/api-optimized"
  push_to_hub: false
  export_formats: ["config"]
  
# Cost and performance requirements
hardware_requirements:
  development:
    min_memory: "1GB"               # Minimal local requirements
    recommended_memory: "2GB"
    disk_space: "100MB"
    estimated_cost: "$1-3/day"
    notes: "API-only, minimal local resources"
    
  production:
    min_memory: "2GB"
    recommended_memory: "4GB"
    disk_space: "500MB"
    estimated_cost: "$5-15/day"
    notes: "Higher volume API usage"
    
  local_fallback:
    min_memory: "4GB"
    recommended_memory: "8GB"
    disk_space: "2GB"
    estimated_time: "2-3 minutes setup"
    notes: "Emergency local backup"

# Environment auto-detection
auto_environment:
  enabled: true
  detection_order:
    - "development"
    - "production"
    - "local_fallback"
    
  selection_criteria:
    development:
      - "os.getenv('ENVIRONMENT', 'dev') == 'dev'"
      - "os.getenv('OPENAI_API_KEY') is not None"
    production:
      - "os.getenv('ENVIRONMENT') == 'production'"
      - "os.getenv('OPENAI_API_KEY') is not None"
    local_fallback:
      - "True"                       # Always available as fallback

# Cost optimization features
cost_optimization:
  enable_caching: true
  prompt_compression: true
  batch_requests: true
  max_tokens_limit: 2000
  cost_alerts:
    daily_threshold: 5.0
    monthly_threshold: 50.0
    
# API routing intelligence
api_routing:
  simple_queries:
    models: ["gpt-4o-mini"]
    max_tokens: 500
    criteria: ["definitions", "basic_qa"]
    
  complex_queries:
    models: ["gpt-4o-mini", "gpt-4o"]
    max_tokens: 2000
    criteria: ["analysis", "reasoning"]
    
# Scaling path to local deployment
scaling:
  api_request_threshold: 10000     # Requests/month before considering local
  monthly_cost_threshold: 100      # Consider local hosting after $100/month
  next_strategy: "hybrid_cloud_local"
  
# Required credentials
required_credentials:
  - "OPENAI_API_KEY"
  - "ANTHROPIC_API_KEY"            # Optional fallback
  - "GROQ_API_KEY"                 # Optional for specific tasks