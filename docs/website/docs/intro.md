---
sidebar_position: 1
sidebar_label: Overview
---

# 🦙 LlamaFarm - Build Powerful AI Locally, Deploy Anywhere

<div align="center">
  <img src="/img/rocket-llama.png" alt="Llama Building a Rocket" width="400"/>
  
  **Empowering developers to build production-ready AI applications with complete local control**
  
  <br/>
  <a href="https://opensource.org/licenses/MIT"><img alt="License: MIT" src="https://img.shields.io/badge/License-MIT-yellow.svg"/></a>
  <a href="https://www.python.org/downloads/"><img alt="Python 3.8+" src="https://img.shields.io/badge/python-3.8+-blue.svg"/></a>
  <a href="https://github.com/llama-farm/llamafarm/blob/main/CONTRIBUTING.md"><img alt="PRs Welcome" src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg"/></a>
</div>

---

## What is LlamaFarm?

LlamaFarm is a modular framework for local-first AI: RAG, model management, prompt engineering, and soon fine‑tuning.

### Our mission

- Local first
- Production ready
- Developer friendly
- Modular and vendor‑neutral

---

## Highlights

- ⚡ Local-first workflows with cloud-on-demand
- 🔌 Plug-and-play components (RAG, Models, Prompts)
- 🧪 Built‑in evaluation and A/B testing
- 🛠️ CLI-first, config‑driven
- 🌈 Accessible theming with light/dark modes

---

## Quick links

- Overview: [Getting started](/docs/overview/getting-started) • [Features](/docs/overview/features) • [Architecture](/docs/overview/architecture) • [Why LlamaFarm](/docs/overview/why-llamafarm) • [Contributing](/docs/overview/contributing) • [Community](/docs/overview/community) • [License](/docs/overview/license) • [Credits](/docs/overview/credits)
- Product: [RAG](/docs/rag) • [Prompts](/docs/prompts) • [Models](/docs/models) • [Configuration](/docs/configuration) • [Deployment](/docs/deployment)
