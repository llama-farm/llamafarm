# Simple to Complex Strategy Examples
# Progressive configurations from basic to advanced use cases
# Demonstrates the flexibility and scalability of the RAG system

# ============================================================================
# LEVEL 1: SIMPLE STRATEGY - Basic Document Search
# ============================================================================
simple_document_search:
  description: "Minimal configuration for basic document search"
  use_cases:
    - "Quick prototyping"
    - "Small document collections"
    - "Personal knowledge base"
  
  components:
    # Simple text parsing - no fancy extraction
    parser:
      type: "TextParser"
      config:
        chunk_size: 512               # Default chunk size
        chunk_overlap: 50             # Minimal overlap
    
    # No extractors - just raw text
    extractors: []
    
    # Basic embeddings
    embedder:
      type: "OllamaEmbedder"
      config:
        model: "nomic-embed-text"
        dimension: 768
    
    # Simple storage
    vector_store:
      type: "ChromaStore"
      config:
        collection_name: "simple_docs"
        persist_directory: "./vectordb/simple"
    
    # Basic similarity search
    retrieval_strategy:
      type: "BasicSimilarityStrategy"
      config:
        top_k: 5                      # Return top 5 results

# ============================================================================
# LEVEL 2: INTERMEDIATE STRATEGY - Enhanced with Metadata
# ============================================================================
intermediate_document_search:
  description: "Add metadata extraction and filtering for better results"
  use_cases:
    - "Small business documents"
    - "Team knowledge sharing"
    - "Project documentation"
  
  components:
    # Same parser but with better chunking
    parser:
      type: "TextParser"
      config:
        chunk_size: 768               # Larger chunks for context
        chunk_overlap: 100            # More overlap
        preserve_formatting: true      # Keep structure
    
    # Add basic extractors
    extractors:
      - type: "KeywordExtractor"      # Extract key terms
        config:
          max_keywords: 10
          algorithm: "yake"
      
      - type: "EntityExtractor"       # Extract people, orgs, dates
        config:
          entities: ["PERSON", "ORG", "DATE"]
    
    # Same embeddings
    embedder:
      type: "OllamaEmbedder"
      config:
        model: "nomic-embed-text"
        dimension: 768
        batch_size: 32                # Process in batches
    
    # Storage with metadata indexing
    vector_store:
      type: "ChromaStore"
      config:
        collection_name: "intermediate_docs"
        persist_directory: "./vectordb/intermediate"
        metadata_config:
          indexed_fields: ["keywords", "entities"]
    
    # Add metadata filtering
    retrieval_strategy:
      type: "MetadataFilteredStrategy"
      config:
        top_k: 10
        filter_mode: "post"           # Filter after retrieval

# ============================================================================
# LEVEL 3: ADVANCED STRATEGY - Multi-format with Reranking
# ============================================================================
advanced_multi_format:
  description: "Handle multiple file formats with intelligent reranking"
  use_cases:
    - "Corporate knowledge management"
    - "Research repositories"
    - "Content management systems"
  
  components:
    # Universal parser for multiple formats
    parser:
      type: "UniversalParser"
      config:
        auto_detect: true             # Detect file format
        parsers:                      # Configure each parser
          pdf:
            extract_tables: true
            extract_images: false
          csv:
            has_header: true
          markdown:
            preserve_formatting: true
        chunk_size: 1024
        chunk_overlap: 200
    
    # Multiple extractors for rich metadata
    extractors:
      - type: "KeywordExtractor"
        config:
          max_keywords: 15
          algorithm: "yake"
      
      - type: "EntityExtractor"
        config:
          entities: ["PERSON", "ORG", "DATE", "GPE", "PRODUCT"]
          confidence_threshold: 0.7
      
      - type: "SummaryExtractor"      # Add summaries
        config:
          max_sentences: 3
          include_keywords: true
      
      - type: "HeadingExtractor"      # Document structure
        config:
          levels: [1, 2, 3]
          include_content: true
    
    # Better embeddings model
    embedder:
      type: "SentenceTransformerEmbedder"  # More accurate
      config:
        model: "all-mpnet-base-v2"
        dimension: 768
        batch_size: 24
        normalize: true
    
    # Advanced storage configuration
    vector_store:
      type: "ChromaStore"
      config:
        collection_name: "advanced_docs"
        persist_directory: "./vectordb/advanced"
        distance_metric: "cosine"
        metadata_config:
          indexed_fields: ["document_type", "date", "author"]
          filterable_fields: ["keywords", "entities"]
    
    # Intelligent reranking
    retrieval_strategy:
      type: "RerankedStrategy"
      config:
        initial_k: 20                 # Get more candidates
        final_k: 5                    # Return best 5
        rerank_factors:
          recency_weight: 0.2         # Prefer recent docs
          relevance_weight: 0.6       # Semantic similarity
          length_weight: 0.2          # Document length preference

# ============================================================================
# LEVEL 4: COMPLEX STRATEGY - Enterprise RAG Pipeline
# ============================================================================
enterprise_rag_pipeline:
  description: "Full-featured enterprise document processing and retrieval"
  use_cases:
    - "Large organization knowledge base"
    - "Compliance and audit systems"
    - "Multi-department documentation"
    - "Global content management"
  
  components:
    # Sophisticated parsing with format detection
    parser:
      type: "EnterpriseParser"
      config:
        auto_detect: true
        parallel_processing: true      # Process files in parallel
        error_handling: "continue"     # Don't stop on errors
        parsers:
          pdf:
            extract_everything: true   # All content types
            ocr_enabled: true         # Handle scanned docs
            language_detection: true
          office:
            extract_comments: true     # Document comments
            extract_revisions: true    # Track changes
            extract_metadata: true
          email:
            extract_attachments: true
            extract_headers: true
          web:
            javascript_rendering: true # Dynamic content
            extract_structured_data: true
        chunk_size: 1024
        chunk_overlap: 256
        adaptive_chunking: true        # Adjust based on content
    
    # Comprehensive extraction pipeline
    extractors:
      # Document classification
      - type: "DocumentClassifier"
        config:
          categories:
            - "legal"
            - "financial"
            - "technical"
            - "hr"
            - "marketing"
          confidence_threshold: 0.8
          multi_label: true
      
      # Advanced NER with custom entities
      - type: "EnterpriseEntityExtractor"
        config:
          standard_entities: ["PERSON", "ORG", "DATE", "MONEY", "PRODUCT"]
          custom_entities:
            - "PROJECT_CODE"
            - "EMPLOYEE_ID"
            - "COST_CENTER"
            - "VENDOR"
            - "CONTRACT_NUMBER"
          entity_linking: true         # Link to knowledge graph
          coreference_resolution: true # Resolve pronouns
      
      # Compliance and regulatory extraction
      - type: "ComplianceExtractor"
        config:
          regulations:
            - "GDPR"
            - "HIPAA"
            - "SOX"
            - "PCI-DSS"
          identify_pii: true
          identify_sensitive: true
          flag_violations: true
      
      # Relationship extraction
      - type: "RelationshipExtractor"
        config:
          relationship_types:
            - "reports_to"            # Org structure
            - "references"            # Document references
            - "supersedes"            # Version control
            - "depends_on"            # Dependencies
          build_graph: true           # Create knowledge graph
      
      # Multi-lingual support
      - type: "MultilingualExtractor"
        config:
          detect_language: true
          supported_languages: ["en", "es", "fr", "de", "zh", "ja"]
          translate_entities: true
          preserve_original: true
      
      # Quality and metrics
      - type: "QualityExtractor"
        config:
          calculate_completeness: true
          calculate_accuracy: true
          identify_gaps: true
          suggest_improvements: true
    
    # Enterprise-grade embeddings
    embedder:
      type: "HybridEmbedder"          # Multiple embedding strategies
      config:
        dense_model:                  # Semantic embeddings
          type: "sentence-transformers/all-mpnet-base-v2"
          dimension: 768
        sparse_model:                  # Keyword embeddings
          type: "splade"
          vocab_size: 30522
        fusion_strategy: "late"        # Late fusion of results
        batch_size: 32
        cache_embeddings: true         # Cache for performance
        distributed: true              # Distributed processing
    
    # Scalable vector storage
    vector_store:
      type: "EnterpriseVectorStore"
      config:
        backend: "qdrant"              # Production-grade DB
        collection_name: "enterprise_docs"
        sharding:
          enabled: true
          num_shards: 4
        replication:
          enabled: true
          num_replicas: 2
        index_config:
          type: "hnsw"
          m: 16
          ef_construction: 200
        metadata_config:
          indexed_fields: [
            "department",
            "document_type",
            "classification",
            "date",
            "author",
            "language"
          ]
          full_text_search: true       # Enable text search
          faceted_search: true         # Enable facets
        security:
          encryption_at_rest: true
          access_control: true
          audit_logging: true
    
    # Sophisticated retrieval with multiple strategies
    retrieval_strategy:
      type: "EnterpriseHybridStrategy"
      config:
        strategies:
          # Semantic search
          - type: "SemanticStrategy"
            weight: 0.4
            config:
              model: "cross-encoder"   # Reranking model
              top_k: 50
          
          # Keyword search (BM25)
          - type: "KeywordStrategy"
            weight: 0.2
            config:
              algorithm: "bm25"
              top_k: 50
          
          # Entity-based search
          - type: "EntityStrategy"
            weight: 0.2
            config:
              entity_matching: true
              relationship_traversal: true
              top_k: 30
          
          # Metadata filtering
          - type: "MetadataStrategy"
            weight: 0.2
            config:
              user_context: true       # Consider user's context
              department_filter: true
              access_control: true
        
        # Advanced fusion and reranking
        fusion:
          method: "reciprocal_rank_fusion"
          normalization: true
        
        reranking:
          enabled: true
          model: "ms-marco-MiniLM-L-12-v2"
          factors:
            relevance: 0.4
            recency: 0.2
            authority: 0.2           # Document authority
            popularity: 0.1          # Usage statistics
            user_preference: 0.1     # Personalization
        
        # Final configuration
        final_k: 10
        diversity_threshold: 0.3      # Ensure diverse results
        explanation: true              # Explain why results were chosen
        
        # Performance optimization
        caching:
          enabled: true
          ttl: 3600
          size: 10000
        
        # Monitoring and analytics
        tracking:
          log_queries: true
          log_performance: true
          log_relevance_feedback: true

# ============================================================================
# LEVEL 5: EXPERT STRATEGY - AI-Powered Adaptive System
# ============================================================================
ai_adaptive_rag_system:
  description: "Self-optimizing RAG system with ML-driven configuration"
  use_cases:
    - "Large-scale AI assistants"
    - "Research platforms"
    - "Automated knowledge discovery"
    - "Continuous learning systems"
  
  components:
    # Adaptive parsing based on content
    parser:
      type: "AdaptiveParser"
      config:
        ml_model: "document-classifier"  # Classify then parse
        optimization_objective: "quality" # quality, speed, or balanced
        dynamic_chunking:
          enabled: true
          min_size: 256
          max_size: 2048
          overlap_ratio: 0.1-0.3       # Adaptive overlap
        continuous_learning: true      # Learn from feedback
    
    # AI-driven extraction
    extractors:
      - type: "LLMExtractor"          # Use LLM for extraction
        config:
          model: "gpt-4"
          tasks:
            - "entities"
            - "relationships"
            - "topics"
            - "intents"
            - "claims"
            - "evidence"
          few_shot_examples: true
          chain_of_thought: true
      
      - type: "AutoMLExtractor"       # Learn extraction patterns
        config:
          learn_from_feedback: true
          online_learning: true
          custom_model_training: true
    
    # Multi-model embeddings
    embedder:
      type: "EnsembleEmbedder"
      config:
        models:
          - "sentence-transformers/all-mpnet-base-v2"
          - "intfloat/e5-large-v2"
          - "BAAI/bge-large-en"
        aggregation: "weighted_average"
        weights: "learned"             # Learn optimal weights
        dimension_reduction:
          enabled: true
          target_dim: 512
          method: "pca"
    
    # Distributed vector storage
    vector_store:
      type: "DistributedVectorStore"
      config:
        backends: ["qdrant", "milvus", "weaviate"]
        routing: "intelligent"         # Route based on query type
        auto_scaling: true
        auto_indexing: true
        continuous_optimization: true
    
    # Self-optimizing retrieval
    retrieval_strategy:
      type: "AdaptiveRetrievalStrategy"
      config:
        base_strategies: ["semantic", "keyword", "graph", "neural"]
        meta_learner: "reinforcement_learning"
        optimization_metrics:
          - "precision"
          - "recall"
          - "diversity"
          - "latency"
        personalization: true
        context_aware: true
        explain_ai: true               # Explainable AI
        continuous_improvement: true
        a_b_testing: true              # Automatic A/B tests